{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "df6d72c4",
      "metadata": {
        "id": "df6d72c4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from tabulate import tabulate\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import argparse\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4365cd18",
      "metadata": {
        "id": "4365cd18"
      },
      "outputs": [],
      "source": [
        "class ResNetCifarBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(ResNetCifarBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "82e7a20d",
      "metadata": {
        "id": "82e7a20d"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 32\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(256, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "85234ed0",
      "metadata": {
        "id": "85234ed0"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(is_train, batch_size, path='./CIFAR10/'):\n",
        "    tr_fl = [transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(0.5),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ]\n",
        "    te_fl = [transforms.ToTensor()\n",
        "            # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "            ]\n",
        "    tr_fl = transforms.Compose(tr_fl)\n",
        "    te_fl = transforms.Compose(te_fl)\n",
        "\n",
        "    if is_train:\n",
        "        train_data = torchvision.datasets.CIFAR10(path, train=True, download=True, transform=tr_fl)\n",
        "        train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "        return train_loader\n",
        "    else:\n",
        "        test_data = torchvision.datasets.CIFAR10(path, train = False, download=True, transform=te_fl)\n",
        "        test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "        return test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b673ddd1",
      "metadata": {
        "id": "b673ddd1"
      },
      "outputs": [],
      "source": [
        "def init_weights(net, gain=0.02):\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, gain)\n",
        "            nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    # net.apply(init_func)\n",
        "    init_func(net)\n",
        "\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "\n",
        "    def __init__(self, opt, train=True):\n",
        "\n",
        "        super(ResNetModel, self).__init__()\n",
        "\n",
        "        self.net = ResNet(ResNetCifarBlock, [3, 6, 4, 3])\n",
        "        if train:\n",
        "            self.net.train()\n",
        "        else:\n",
        "            self.net.eval()\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device('cuda')\n",
        "            self.net = self.net.to('cuda')\n",
        "            self.net = torch.nn.DataParallel(self.net)\n",
        "        else:\n",
        "            self.device = torch.device('mps')\n",
        "            self.net = self.net.to('mps')\n",
        "            self.net = torch.nn.DataParallel(self.net)\n",
        "\n",
        "        init_weights(self.net)\n",
        "        num_params = 0\n",
        "        for param in self.net.parameters():\n",
        "            num_params += param.numel()\n",
        "\n",
        "        self.num_params = num_params\n",
        "\n",
        "        layer_info = []\n",
        "\n",
        "        for name, param in self.net.named_parameters():\n",
        "            name = name.split('.')\n",
        "            name = str(name[-2]) + '.' + str(name[-1])\n",
        "            layer_info.append([name, param.numel()])\n",
        "\n",
        "        self.para_table = tabulate(layer_info, headers=['Layers', 'size'], tablefmt='grid')\n",
        "\n",
        "        self.timestamp = opt.timestamp\n",
        "\n",
        "        if train:\n",
        "            self.checkpoint_dir = opt.checkpoint_dir\n",
        "\n",
        "            assert opt.optimizer in ['SGD', 'Adam', 'ASGD',\n",
        "                                     'Adagrad'], \"Input optimization is not valid, please specify among  ['SGD', 'Adam', 'ASGD', 'Adagrad'] \"\n",
        "\n",
        "            if opt.optimizer == 'SGD':\n",
        "                self.optimizer = optim.SGD(\n",
        "                    self.net.parameters(),\n",
        "                    lr=opt.lr,\n",
        "                    momentum=opt.momentum,\n",
        "                    weight_decay=opt.weight_decay\n",
        "                )\n",
        "            if opt.optimizer == 'Adam':\n",
        "                self.optimizer = optim.Adam(\n",
        "                    self.net.parameters(),\n",
        "                    lr=opt.lr,\n",
        "                    weight_decay=opt.weight_decay\n",
        "                )\n",
        "            if opt.optimizer == 'Adagrad':\n",
        "                self.optimizer = optim.Adagrad(\n",
        "                    self.net.parameters(),\n",
        "                    lr=opt.lr,\n",
        "                    #lr_decay=opt.lr_decay,\n",
        "                    weight_decay=opt.weight_decay\n",
        "                )\n",
        "            if opt.optimizer == 'ASGD':\n",
        "                self.optimizer = optim.ASGD(\n",
        "                    self.net.parameters(),\n",
        "                    lr=opt.lr,\n",
        "                    weight_decay=opt.weight_decay\n",
        "                )\n",
        "\n",
        "            self.scheduler = optim.lr_scheduler.StepLR(\n",
        "                self.optimizer,\n",
        "                step_size=opt.decay_step,\n",
        "                gamma=opt.lr_decay_rate\n",
        "            )\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "            self.loss = 0.0\n",
        "\n",
        "    def optimize_params(self, x, label):\n",
        "        x = x.to(self.device)\n",
        "        label = label.to(self.device)\n",
        "        y = self._forward(x)\n",
        "        self._update_params(y, label)\n",
        "\n",
        "    def _forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "\n",
        "    def _backward(self, y, label):\n",
        "        self.loss = self.criterion(y, label)\n",
        "        self.loss.backward()\n",
        "\n",
        "    def _update_params(self, y, label):\n",
        "        self.optimizer.zero_grad()\n",
        "        self._backward(y, label)\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step()  # scheduler step in each iteration\n",
        "\n",
        "    def test(self, x, label):\n",
        "        with torch.no_grad():\n",
        "            x = x.to(self.device)\n",
        "            label = label.to(self.device)\n",
        "            outputs = self._forward(x)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total = label.size(0)\n",
        "            correct = (predicted == label).sum().item()\n",
        "            return correct, total, predicted\n",
        "\n",
        "    def val(self, x, label):\n",
        "        with torch.no_grad():\n",
        "            x = x.to(self.device)\n",
        "            label = label.to(self.device)\n",
        "            y = self._forward(x)\n",
        "            return self.criterion(y, label).item()\n",
        "\n",
        "    def save_model(self):\n",
        "\n",
        "        timestamp = self.timestamp\n",
        "        file_name = 'final_' + timestamp\n",
        "\n",
        "        path = os.path.join(self.checkpoint_dir, f'{file_name}.pth')\n",
        "        torch.save(self.net.state_dict(), path)\n",
        "        print(f'model saved to {path}')\n",
        "\n",
        "        return path\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.net.load_state_dict(torch.load(path))\n",
        "        print(f'model loaded from {path}')\n",
        "\n",
        "    def get_current_loss(self):\n",
        "        return self.loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c71dc25a",
      "metadata": {
        "id": "c71dc25a"
      },
      "outputs": [],
      "source": [
        "def train(opt):\n",
        "    print(opt)\n",
        "\n",
        "    dataloader = get_dataloader(True, opt.batch, opt.dataset_dir)\n",
        "    model = ResNetModel(opt, train=True)\n",
        "\n",
        "    num_params = model.num_params\n",
        "\n",
        "    timestamp = opt.timestamp\n",
        "\n",
        "    with open(os.path.join(opt.checkpoint_dir, 'log_' + timestamp + '.txt'), 'a') as f:\n",
        "        f.write(str(opt) + '\\n')\n",
        "        f.write('\\nThe total number of parameter is: ' + str(round(num_params / 1e6, 3)) + ' M' + '\\n')\n",
        "\n",
        "    with open(os.path.join(opt.checkpoint_dir, timestamp + 'para_table.txt'), 'a') as t:\n",
        "        t.write('Total number of parameters: ' + str(round(num_params / 1e6, 3)) + 'M' + '\\n')\n",
        "        t.write('batch size: ' + str(opt.batch) + '\\n')\n",
        "        #t.write('Depth of network:' + str(opt.n) + '\\n')\n",
        "        t.write(model.para_table)\n",
        "\n",
        "    total_iter = 0\n",
        "    loss = 0.0\n",
        "    train_loss_history = []\n",
        "\n",
        "    while True:\n",
        "        for batch in dataloader:\n",
        "            total_iter += 1\n",
        "            inputs, labels = batch\n",
        "            model.optimize_params(inputs, labels)\n",
        "            loss += model.get_current_loss()\n",
        "\n",
        "            if total_iter % opt.print_freq == 0:\n",
        "                txt = f'iter: {total_iter: 6d}, loss: {loss / opt.print_freq}'\n",
        "                train_loss_history += [loss / opt.print_freq]\n",
        "\n",
        "                print(txt)\n",
        "\n",
        "                with open(os.path.join(opt.checkpoint_dir, 'log_' + timestamp + '.txt'), 'a') as f:\n",
        "                    f.write(txt + '\\n')\n",
        "\n",
        "                loss = 0.0\n",
        "\n",
        "            if total_iter == opt.num_iter:\n",
        "                model_path = model.save_model()\n",
        "\n",
        "                return train_loss_history, model_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(opt, path):\n",
        "    dataloader = get_dataloader(False, opt.batch, opt.dataset_dir)\n",
        "    model = ResNetModel(opt, train=False)\n",
        "    model.load_model(path)\n",
        "\n",
        "    total_n = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        inputs, labels = batch\n",
        "        correct, total, _ = model.test(inputs, labels)\n",
        "        total_correct += correct\n",
        "        total_n += total\n",
        "\n",
        "    acc = 100 * total_correct / total_n\n",
        "    err = 100 - acc\n",
        "\n",
        "    timestamp = opt.timestamp\n",
        "\n",
        "    with open(os.path.join(opt.checkpoint_dir, 'log_' + timestamp + '.txt'), 'a') as f:\n",
        "        f.write('\\nThe final accuracy is: ' + str(round(acc, 3)) + '\\n')\n",
        "        f.write('The final error is: ' + str(round(err, 3)) + '\\n')\n",
        "        f.write('correct ratio is: ' + str(round(total_correct / total_n, 3)) + '\\n')\n",
        "\n",
        "    return acc,err"
      ],
      "metadata": {
        "id": "Lom8F48oIVjf"
      },
      "id": "Lom8F48oIVjf",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "1509ef04",
      "metadata": {
        "id": "1509ef04"
      },
      "outputs": [],
      "source": [
        "def parse_args():\n",
        "    timestamp = datetime.now().strftime(\"%m%d%H%M%S\")\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--batch', help='batch size', type=int, default=128)\n",
        "    parser.add_argument('--timestamp', help='timestamp', type=str, default=timestamp)\n",
        "\n",
        "    parser.add_argument('--dataset_dir', default='./dataset')\n",
        "    parser.add_argument('--checkpoint_dir', default='./checkpoint')\n",
        "\n",
        "    parser.add_argument('--print_freq', help='print loss freq', type=int, default=100)\n",
        "    parser.add_argument('--optimizer', help='optimizer', type=str, default='SGD')\n",
        "    parser.add_argument('--lr', help='initial learning rate', type=float, default=0.3)\n",
        "    parser.add_argument('--momentum', help='optimizer momentum', type=float, default=0.9)\n",
        "    parser.add_argument('--weight_decay', help='optimizer weight decay (L2 reg.)', type=float, default=0.0001)\n",
        "    parser.add_argument('--decay_step', help='learning rate decay in every step', type=int, default=10000)\n",
        "    parser.add_argument('--lr_decay_rate', help='lr *= lr_decay_rate at decay_lr_i-th iteration', type=float,\n",
        "                        default=0.3)\n",
        "    parser.add_argument('--num_iter', help='number of iterations', type=int, default=32000)\n",
        "    args = parser.parse_args(args=[])\n",
        "\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "20f89fd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20f89fd0",
        "outputId": "82185e03-6578-487f-955c-1e4a8980cee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch=128, timestamp='0407002842', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='SGD', lr=0.3, momentum=0.9, weight_decay=0.0001, decay_step=10000, lr_decay_rate=0.3, num_iter=32000)\n",
            "Files already downloaded and verified\n",
            "iter:    100, loss: 2.8179682731628417\n",
            "iter:    200, loss: 2.2983600664138795\n",
            "iter:    300, loss: 2.276985967159271\n",
            "iter:    400, loss: 2.227575132846832\n",
            "iter:    500, loss: 2.1088115215301513\n",
            "iter:    600, loss: 1.9756933927536011\n",
            "iter:    700, loss: 1.8799326515197754\n",
            "iter:    800, loss: 1.8334396290779114\n",
            "iter:    900, loss: 1.7641287064552307\n",
            "iter:   1000, loss: 1.7182425034046174\n",
            "iter:   1100, loss: 1.6809736740589143\n",
            "iter:   1200, loss: 1.6484185814857484\n",
            "iter:   1300, loss: 1.5922217071056366\n",
            "iter:   1400, loss: 1.5536415731906892\n",
            "iter:   1500, loss: 1.5209322154521943\n",
            "iter:   1600, loss: 1.494431495666504\n",
            "iter:   1700, loss: 1.4642040455341339\n",
            "iter:   1800, loss: 1.4270201241970062\n",
            "iter:   1900, loss: 1.3955844593048097\n",
            "iter:   2000, loss: 1.3655935859680175\n",
            "iter:   2100, loss: 1.3449482357501983\n",
            "iter:   2200, loss: 1.288564876317978\n",
            "iter:   2300, loss: 1.26809379696846\n",
            "iter:   2400, loss: 1.2475946658849717\n",
            "iter:   2500, loss: 1.218888716697693\n",
            "iter:   2600, loss: 1.1977031433582306\n",
            "iter:   2700, loss: 1.1363860553503036\n",
            "iter:   2800, loss: 1.0991261130571366\n",
            "iter:   2900, loss: 1.0901041519641876\n",
            "iter:   3000, loss: 1.0551646423339844\n",
            "iter:   3100, loss: 1.0030678749084472\n",
            "iter:   3200, loss: 0.991926560997963\n",
            "iter:   3300, loss: 0.9621267783641815\n",
            "iter:   3400, loss: 0.9515210795402527\n",
            "iter:   3500, loss: 0.9488881462812424\n",
            "iter:   3600, loss: 0.8982763946056366\n",
            "iter:   3700, loss: 0.891655240058899\n",
            "iter:   3800, loss: 0.8806189215183258\n",
            "iter:   3900, loss: 0.8686507964134216\n",
            "iter:   4000, loss: 0.822809772491455\n",
            "iter:   4100, loss: 0.8274394601583481\n",
            "iter:   4200, loss: 0.7980687707662583\n",
            "iter:   4300, loss: 0.8070112377405166\n",
            "iter:   4400, loss: 0.7604710513353348\n",
            "iter:   4500, loss: 0.7590220636129379\n",
            "iter:   4600, loss: 0.7519769549369812\n",
            "iter:   4700, loss: 0.7600923025608063\n",
            "iter:   4800, loss: 0.7057988518476486\n",
            "iter:   4900, loss: 0.7429971021413803\n",
            "iter:   5000, loss: 0.7058178928494453\n",
            "iter:   5100, loss: 0.6860874167084694\n",
            "iter:   5200, loss: 0.6740195998549461\n",
            "iter:   5300, loss: 0.6927756041288375\n",
            "iter:   5400, loss: 0.6680251201987266\n",
            "iter:   5500, loss: 0.6630991798639297\n",
            "iter:   5600, loss: 0.6538177335262298\n",
            "iter:   5700, loss: 0.6350576683878899\n",
            "iter:   5800, loss: 0.6387260872125625\n",
            "iter:   5900, loss: 0.6402874618768692\n",
            "iter:   6000, loss: 0.6180216804146766\n",
            "iter:   6100, loss: 0.6135428661108017\n",
            "iter:   6200, loss: 0.6134318214654922\n",
            "iter:   6300, loss: 0.5883956348896027\n",
            "iter:   6400, loss: 0.5891633993387222\n",
            "iter:   6500, loss: 0.5941742175817489\n",
            "iter:   6600, loss: 0.5824846148490905\n",
            "iter:   6700, loss: 0.5523029592633247\n",
            "iter:   6800, loss: 0.571436057984829\n",
            "iter:   6900, loss: 0.5626859164237976\n",
            "iter:   7000, loss: 0.548859523832798\n",
            "iter:   7100, loss: 0.5336457341909409\n",
            "iter:   7200, loss: 0.5329842358827591\n",
            "iter:   7300, loss: 0.5443640694022178\n",
            "iter:   7400, loss: 0.537114424109459\n",
            "iter:   7500, loss: 0.5048789426684379\n",
            "iter:   7600, loss: 0.5102866026759147\n",
            "iter:   7700, loss: 0.5361721464991569\n",
            "iter:   7800, loss: 0.5219669824838639\n",
            "iter:   7900, loss: 0.4981446439027786\n",
            "iter:   8000, loss: 0.5051177215576171\n",
            "iter:   8100, loss: 0.498049131333828\n",
            "iter:   8200, loss: 0.5015275970101356\n",
            "iter:   8300, loss: 0.4916279563307762\n",
            "iter:   8400, loss: 0.4910410225391388\n",
            "iter:   8500, loss: 0.4791770446300507\n",
            "iter:   8600, loss: 0.5066644600033761\n",
            "iter:   8700, loss: 0.45961828380823133\n",
            "iter:   8800, loss: 0.461290934830904\n",
            "iter:   8900, loss: 0.4785347726941109\n",
            "iter:   9000, loss: 0.4808799034357071\n",
            "iter:   9100, loss: 0.4518614920973778\n",
            "iter:   9200, loss: 0.4515072849392891\n",
            "iter:   9300, loss: 0.46725712567567823\n",
            "iter:   9400, loss: 0.45357515186071395\n",
            "iter:   9500, loss: 0.44141823798418045\n",
            "iter:   9600, loss: 0.4342615368962288\n",
            "iter:   9700, loss: 0.437101349234581\n",
            "iter:   9800, loss: 0.4500177279114723\n",
            "iter:   9900, loss: 0.42037113919854163\n",
            "iter:  10000, loss: 0.4337602135539055\n",
            "iter:  10100, loss: 0.3389040149748325\n",
            "iter:  10200, loss: 0.29762387126684187\n",
            "iter:  10300, loss: 0.2641623690724373\n",
            "iter:  10400, loss: 0.27087556511163713\n",
            "iter:  10500, loss: 0.26702384650707245\n",
            "iter:  10600, loss: 0.24235042840242385\n",
            "iter:  10700, loss: 0.23865942046046257\n",
            "iter:  10800, loss: 0.2485042490810156\n",
            "iter:  10900, loss: 0.2431949970126152\n",
            "iter:  11000, loss: 0.23722125701606273\n",
            "iter:  11100, loss: 0.22362739369273185\n",
            "iter:  11200, loss: 0.2316091652959585\n",
            "iter:  11300, loss: 0.2364033431559801\n",
            "iter:  11400, loss: 0.22251208633184433\n",
            "iter:  11500, loss: 0.21497276142239571\n",
            "iter:  11600, loss: 0.2217995335161686\n",
            "iter:  11700, loss: 0.22454691246151925\n",
            "iter:  11800, loss: 0.20139607325196265\n",
            "iter:  11900, loss: 0.20603549286723136\n",
            "iter:  12000, loss: 0.2136334254592657\n",
            "iter:  12100, loss: 0.2256387220323086\n",
            "iter:  12200, loss: 0.20330406852066518\n",
            "iter:  12300, loss: 0.1949624077230692\n",
            "iter:  12400, loss: 0.21191991686820985\n",
            "iter:  12500, loss: 0.2217968726158142\n",
            "iter:  12600, loss: 0.19795474864542484\n",
            "iter:  12700, loss: 0.20231142960488796\n",
            "iter:  12800, loss: 0.22196797631680965\n",
            "iter:  12900, loss: 0.2115707004070282\n",
            "iter:  13000, loss: 0.1930277180671692\n",
            "iter:  13100, loss: 0.20823965452611445\n",
            "iter:  13200, loss: 0.20623360097408294\n",
            "iter:  13300, loss: 0.19495210886001588\n",
            "iter:  13400, loss: 0.19384119354188442\n",
            "iter:  13500, loss: 0.2012152713537216\n",
            "iter:  13600, loss: 0.19962486393749715\n",
            "iter:  13700, loss: 0.2108785282820463\n",
            "iter:  13800, loss: 0.190173334851861\n",
            "iter:  13900, loss: 0.20098290026187896\n",
            "iter:  14000, loss: 0.19538672603666782\n",
            "iter:  14100, loss: 0.20466201342642307\n",
            "iter:  14200, loss: 0.19642168805003166\n",
            "iter:  14300, loss: 0.19613972842693328\n",
            "iter:  14400, loss: 0.19550776228308678\n",
            "iter:  14500, loss: 0.20606605052948\n",
            "iter:  14600, loss: 0.17905888676643372\n",
            "iter:  14700, loss: 0.20546715371310711\n",
            "iter:  14800, loss: 0.2041880728304386\n",
            "iter:  14900, loss: 0.1849971864372492\n",
            "iter:  15000, loss: 0.1804724368453026\n",
            "iter:  15100, loss: 0.19827688567340374\n",
            "iter:  15200, loss: 0.19978733107447624\n",
            "iter:  15300, loss: 0.19013712964951993\n",
            "iter:  15400, loss: 0.17848663724958896\n",
            "iter:  15500, loss: 0.1890967508405447\n",
            "iter:  15600, loss: 0.19240820661187172\n",
            "iter:  15700, loss: 0.1790750128403306\n",
            "iter:  15800, loss: 0.17954289384186267\n",
            "iter:  15900, loss: 0.19426125794649124\n",
            "iter:  16000, loss: 0.2063871481269598\n",
            "iter:  16100, loss: 0.17934615805745124\n",
            "iter:  16200, loss: 0.19119780726730823\n",
            "iter:  16300, loss: 0.19670733295381068\n",
            "iter:  16400, loss: 0.19014140501618385\n",
            "iter:  16500, loss: 0.18310931585729123\n",
            "iter:  16600, loss: 0.1862736728042364\n",
            "iter:  16700, loss: 0.1836913087964058\n",
            "iter:  16800, loss: 0.19771296694874763\n",
            "iter:  16900, loss: 0.16305155701935292\n",
            "iter:  17000, loss: 0.17242458529770374\n",
            "iter:  17100, loss: 0.1882285590469837\n",
            "iter:  17200, loss: 0.1926411671936512\n",
            "iter:  17300, loss: 0.17111328504979612\n",
            "iter:  17400, loss: 0.17821458004415036\n",
            "iter:  17500, loss: 0.18298228770494462\n",
            "iter:  17600, loss: 0.18870940126478672\n",
            "iter:  17700, loss: 0.17833091109991073\n",
            "iter:  17800, loss: 0.16809753239154815\n",
            "iter:  17900, loss: 0.17842525959014893\n",
            "iter:  18000, loss: 0.17898995183408262\n",
            "iter:  18100, loss: 0.16524925000965596\n",
            "iter:  18200, loss: 0.1716353563219309\n",
            "iter:  18300, loss: 0.19176949746906757\n",
            "iter:  18400, loss: 0.175546732917428\n",
            "iter:  18500, loss: 0.16100124977529048\n",
            "iter:  18600, loss: 0.17524541445076466\n",
            "iter:  18700, loss: 0.1879995968937874\n",
            "iter:  18800, loss: 0.17285915069282054\n",
            "iter:  18900, loss: 0.14176658272743226\n",
            "iter:  19000, loss: 0.18038399010896683\n",
            "iter:  19100, loss: 0.18970317184925078\n",
            "iter:  19200, loss: 0.17101350758224726\n",
            "iter:  19300, loss: 0.15851349204778672\n",
            "iter:  19400, loss: 0.16468597188591957\n",
            "iter:  19500, loss: 0.17774795301258564\n",
            "iter:  19600, loss: 0.16613765511661768\n",
            "iter:  19700, loss: 0.15994034711271524\n",
            "iter:  19800, loss: 0.16416697356849907\n",
            "iter:  19900, loss: 0.17718311823904515\n",
            "iter:  20000, loss: 0.15478296786546708\n",
            "iter:  20100, loss: 0.1112752502039075\n",
            "iter:  20200, loss: 0.09749299813061953\n",
            "iter:  20300, loss: 0.08163294674828649\n",
            "iter:  20400, loss: 0.07062741065397858\n",
            "iter:  20500, loss: 0.061573136486113074\n",
            "iter:  20600, loss: 0.06644001204520464\n",
            "iter:  20700, loss: 0.058295881543308496\n",
            "iter:  20800, loss: 0.05470376147888601\n",
            "iter:  20900, loss: 0.054613670753315094\n",
            "iter:  21000, loss: 0.05479119914583862\n",
            "iter:  21100, loss: 0.05399952543433756\n",
            "iter:  21200, loss: 0.04598965078126639\n",
            "iter:  21300, loss: 0.050143995452672244\n",
            "iter:  21400, loss: 0.046981729222461584\n",
            "iter:  21500, loss: 0.048704135324805976\n",
            "iter:  21600, loss: 0.03926834671758115\n",
            "iter:  21700, loss: 0.044245771104469894\n",
            "iter:  21800, loss: 0.043681457000784574\n",
            "iter:  21900, loss: 0.045693702949211004\n",
            "iter:  22000, loss: 0.043087264937348664\n",
            "iter:  22100, loss: 0.04126776752760634\n",
            "iter:  22200, loss: 0.04357062453404069\n",
            "iter:  22300, loss: 0.04278684922028333\n",
            "iter:  22400, loss: 0.03905770743731409\n",
            "iter:  22500, loss: 0.03406907933298498\n",
            "iter:  22600, loss: 0.040408119265921416\n",
            "iter:  22700, loss: 0.046423050547018646\n",
            "iter:  22800, loss: 0.03816513470374048\n",
            "iter:  22900, loss: 0.03594518289901316\n",
            "iter:  23000, loss: 0.03743980252649635\n",
            "iter:  23100, loss: 0.03479039903962985\n",
            "iter:  23200, loss: 0.033728947844356295\n",
            "iter:  23300, loss: 0.03499782762490213\n",
            "iter:  23400, loss: 0.03794663636712357\n",
            "iter:  23500, loss: 0.03701113970018923\n",
            "iter:  23600, loss: 0.033180378465913235\n",
            "iter:  23700, loss: 0.03646161563694477\n",
            "iter:  23800, loss: 0.03838570851832628\n",
            "iter:  23900, loss: 0.03164468358270824\n",
            "iter:  24000, loss: 0.03531583438627422\n",
            "iter:  24100, loss: 0.03207694654352963\n",
            "iter:  24200, loss: 0.03852886995999143\n",
            "iter:  24300, loss: 0.035859986988361923\n",
            "iter:  24400, loss: 0.036524039274081585\n",
            "iter:  24500, loss: 0.030003118803724648\n",
            "iter:  24600, loss: 0.040975337768904864\n",
            "iter:  24700, loss: 0.034855386540293694\n",
            "iter:  24800, loss: 0.03131658707978204\n",
            "iter:  24900, loss: 0.029482389579061418\n",
            "iter:  25000, loss: 0.033360159953590485\n",
            "iter:  25100, loss: 0.03206898777512834\n",
            "iter:  25200, loss: 0.029416471270378677\n",
            "iter:  25300, loss: 0.03034230784047395\n",
            "iter:  25400, loss: 0.033818808342330156\n",
            "iter:  25500, loss: 0.029521646136417987\n",
            "iter:  25600, loss: 0.03308871674351394\n",
            "iter:  25700, loss: 0.03411195787601173\n",
            "iter:  25800, loss: 0.041446773721836506\n",
            "iter:  25900, loss: 0.031293952823616564\n",
            "iter:  26000, loss: 0.0339268457936123\n",
            "iter:  26100, loss: 0.032275396983604876\n",
            "iter:  26200, loss: 0.04259135203436017\n",
            "iter:  26300, loss: 0.03975876139476895\n",
            "iter:  26400, loss: 0.029612245755270123\n",
            "iter:  26500, loss: 0.03377287039998919\n",
            "iter:  26600, loss: 0.030372882252559064\n",
            "iter:  26700, loss: 0.030794358043931425\n",
            "iter:  26800, loss: 0.028727313147392124\n",
            "iter:  26900, loss: 0.040398850557394325\n",
            "iter:  27000, loss: 0.03470711552537978\n",
            "iter:  27100, loss: 0.03229048452805728\n",
            "iter:  27200, loss: 0.03495649074669927\n",
            "iter:  27300, loss: 0.03391813892638311\n",
            "iter:  27400, loss: 0.03324449384585023\n",
            "iter:  27500, loss: 0.0314744775602594\n",
            "iter:  27600, loss: 0.030218355713877827\n",
            "iter:  27700, loss: 0.028882746221497654\n",
            "iter:  27800, loss: 0.029252002213615923\n",
            "iter:  27900, loss: 0.032989956331439314\n",
            "iter:  28000, loss: 0.034478833507746456\n",
            "iter:  28100, loss: 0.03405894997995347\n",
            "iter:  28200, loss: 0.030456486390903592\n",
            "iter:  28300, loss: 0.03353452591691166\n",
            "iter:  28400, loss: 0.03760994383599609\n",
            "iter:  28500, loss: 0.03229704609839246\n",
            "iter:  28600, loss: 0.030203008204698564\n",
            "iter:  28700, loss: 0.0388536020508036\n",
            "iter:  28800, loss: 0.03542519652284682\n",
            "iter:  28900, loss: 0.034834208968095484\n",
            "iter:  29000, loss: 0.04168404000345618\n",
            "iter:  29100, loss: 0.03168255108641461\n",
            "iter:  29200, loss: 0.03467152391094715\n",
            "iter:  29300, loss: 0.03621345617808402\n",
            "iter:  29400, loss: 0.031929561719298366\n",
            "iter:  29500, loss: 0.029817047622054817\n",
            "iter:  29600, loss: 0.040139053231105205\n",
            "iter:  29700, loss: 0.03986610206775367\n",
            "iter:  29800, loss: 0.037235884279944\n",
            "iter:  29900, loss: 0.032585927755571904\n",
            "iter:  30000, loss: 0.03563091088552028\n",
            "iter:  30100, loss: 0.028358998352196067\n",
            "iter:  30200, loss: 0.0186452756007202\n",
            "iter:  30300, loss: 0.015315112441312522\n",
            "iter:  30400, loss: 0.011323848867323249\n",
            "iter:  30500, loss: 0.014183625044533982\n",
            "iter:  30600, loss: 0.010150454216636717\n",
            "iter:  30700, loss: 0.012294944110326469\n",
            "iter:  30800, loss: 0.011838683580281213\n",
            "iter:  30900, loss: 0.011414767010137439\n",
            "iter:  31000, loss: 0.00797281849605497\n",
            "iter:  31100, loss: 0.009233319885679521\n",
            "iter:  31200, loss: 0.010373274676967413\n",
            "iter:  31300, loss: 0.009556697780499234\n",
            "iter:  31400, loss: 0.007114857997512445\n",
            "iter:  31500, loss: 0.009397352561354638\n",
            "iter:  31600, loss: 0.00961191137554124\n",
            "iter:  31700, loss: 0.009603442021179943\n",
            "iter:  31800, loss: 0.006953932136530057\n",
            "iter:  31900, loss: 0.008632760659675115\n",
            "iter:  32000, loss: 0.008813079351675697\n",
            "model saved to ./checkpoint/final_0407002842.pth\n",
            "Files already downloaded and verified\n",
            "model loaded from ./checkpoint/final_0407002842.pth\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    args = parse_args()\n",
        "    if not os.path.exists(args.checkpoint_dir):\n",
        "        os.mkdir(args.checkpoint_dir)\n",
        "    loss_history, path = train(args)\n",
        "    test(args, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "1b73478d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "1b73478d",
        "outputId": "bebab714-098f-4af6-b0dd-3e4cfd2ab213"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ed72f196c20>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(loss_history)), loss_history, '-', linewidth=3, label='Train error')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}