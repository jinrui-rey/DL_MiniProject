Namespace(batch=64, timestamp='0406170207', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='SGD', lr=0.5, momentum=0.9, weight_decay=0.0001, decay_step=5000, lr_decay_rate=0.2, num_iter=32000)

The total number of parameter is: 4.884 M
iter:    100, loss: 3.184020895957947
iter:    200, loss: 2.319716601371765
iter:    300, loss: 2.3277174067497253
iter:    400, loss: 2.3196833181381225
iter:    500, loss: 2.320157012939453
iter:    600, loss: 2.3207525324821474
iter:    700, loss: 2.320818145275116
iter:    800, loss: 2.319390993118286
iter:    900, loss: 2.3185730242729186
iter:   1000, loss: 2.321153976917267
iter:   1100, loss: 2.3197368288040163
iter:   1200, loss: 2.314674987792969
iter:   1300, loss: 2.3181625175476075
iter:   1400, loss: 2.3207856178283692
iter:   1500, loss: 2.320960862636566
iter:   1600, loss: 2.3238891673088076
iter:   1700, loss: 2.3141311836242675
iter:   1800, loss: 2.295368499755859
iter:   1900, loss: 2.1936362099647524
iter:   2000, loss: 2.1509099757671355
iter:   2100, loss: 2.1076147043704987
iter:   2200, loss: 2.086647125482559
iter:   2300, loss: 2.032983568906784
iter:   2400, loss: 1.941678922176361
iter:   2500, loss: 1.9192606699466705
iter:   2600, loss: 1.884884248971939
iter:   2700, loss: 1.8249937605857849
iter:   2800, loss: 1.8023159980773926
iter:   2900, loss: 1.7838876819610596
iter:   3000, loss: 1.7256110775470734
iter:   3100, loss: 1.6998649001121522
iter:   3200, loss: 1.6929900968074798
iter:   3300, loss: 1.6067598581314086
iter:   3400, loss: 1.6298018598556518
iter:   3500, loss: 1.5852002108097076
iter:   3600, loss: 1.551038885116577
iter:   3700, loss: 1.5132964181900024
iter:   3800, loss: 1.499638032913208
iter:   3900, loss: 1.4694985461235046
iter:   4000, loss: 1.4493103623390198
iter:   4100, loss: 1.4048181343078614
iter:   4200, loss: 1.4042467498779296
iter:   4300, loss: 1.3734191393852233
iter:   4400, loss: 1.3254912054538728
iter:   4500, loss: 1.3129649305343627
iter:   4600, loss: 1.298599287867546
iter:   4700, loss: 1.2978381824493408
iter:   4800, loss: 1.2770535969734191
iter:   4900, loss: 1.2612248748540877
iter:   5000, loss: 1.2303309881687163
iter:   5100, loss: 1.0730469179153443
iter:   5200, loss: 1.015389816761017
iter:   5300, loss: 1.0137196612358093
iter:   5400, loss: 0.9823618125915528
iter:   5500, loss: 0.9799113702774048
iter:   5600, loss: 0.936040716767311
iter:   5700, loss: 0.9090515321493149
iter:   5800, loss: 0.9267423230409623
iter:   5900, loss: 0.9078778403997422
iter:   6000, loss: 0.8721360754966736
iter:   6100, loss: 0.8823478651046753
iter:   6200, loss: 0.8846610587835312
iter:   6300, loss: 0.8570987224578858
iter:   6400, loss: 0.8509114980697632
iter:   6500, loss: 0.8781004357337951
iter:   6600, loss: 0.8233586186170578
iter:   6700, loss: 0.8161261940002441
iter:   6800, loss: 0.7960862684249878
iter:   6900, loss: 0.7913601404428482
iter:   7000, loss: 0.788314670920372
iter:   7100, loss: 0.7952481663227081
iter:   7200, loss: 0.7356684842705726
iter:   7300, loss: 0.7612279295921326
iter:   7400, loss: 0.7449053049087524
iter:   7500, loss: 0.7483241966366768
iter:   7600, loss: 0.7502823656797409
iter:   7700, loss: 0.73623265594244
iter:   7800, loss: 0.7586067968606949
iter:   7900, loss: 0.7072274231910706
iter:   8000, loss: 0.7300537985563278
iter:   8100, loss: 0.7144272533059121
iter:   8200, loss: 0.7011340385675431
iter:   8300, loss: 0.703817771077156
iter:   8400, loss: 0.6921119284629822
iter:   8500, loss: 0.6873472231626511
iter:   8600, loss: 0.7008170133829117
iter:   8700, loss: 0.664109684228897
iter:   8800, loss: 0.6714126500487327
iter:   8900, loss: 0.6591056311130523
iter:   9000, loss: 0.6661043953895569
iter:   9100, loss: 0.6579045617580414
iter:   9200, loss: 0.6447637945413589
iter:   9300, loss: 0.6702585899829865
iter:   9400, loss: 0.6793005046248436
iter:   9500, loss: 0.6341289409995079
iter:   9600, loss: 0.6312837284803391
iter:   9700, loss: 0.6105434623360634
iter:   9800, loss: 0.6424808228015899
iter:   9900, loss: 0.6218861147761345
iter:  10000, loss: 0.6105239510536193
iter:  10100, loss: 0.5467483457922936
iter:  10200, loss: 0.5088457760214805
iter:  10300, loss: 0.47501682475209234
iter:  10400, loss: 0.48868388310074806
iter:  10500, loss: 0.46183891385793685
iter:  10600, loss: 0.4739188325405121
iter:  10700, loss: 0.46832011073827745
iter:  10800, loss: 0.47640620708465575
iter:  10900, loss: 0.4660699352622032
iter:  11000, loss: 0.4556853796541691
iter:  11100, loss: 0.41813247933983805
iter:  11200, loss: 0.4607150086760521
iter:  11300, loss: 0.43758771136403085
iter:  11400, loss: 0.44882058337330816
iter:  11500, loss: 0.42646931648254394
iter:  11600, loss: 0.4417270065844059
iter:  11700, loss: 0.43258804097771647
iter:  11800, loss: 0.4100324347615242
iter:  11900, loss: 0.42357335075736047
iter:  12000, loss: 0.4181538225710392
iter:  12100, loss: 0.42475938573479655
iter:  12200, loss: 0.4188354988396168
iter:  12300, loss: 0.4238180446624756
iter:  12400, loss: 0.4218091385066509
iter:  12500, loss: 0.4161998426914215
iter:  12600, loss: 0.4150833471119404
iter:  12700, loss: 0.41101039841771125
iter:  12800, loss: 0.39422054871916773
iter:  12900, loss: 0.42020379602909086
iter:  13000, loss: 0.40920655310153964
iter:  13100, loss: 0.3841017584502697
iter:  13200, loss: 0.40200834050774575
iter:  13300, loss: 0.3961353647708893
iter:  13400, loss: 0.3747435492277145
iter:  13500, loss: 0.39455846562981606
iter:  13600, loss: 0.37625052630901334
iter:  13700, loss: 0.38498946115374566
iter:  13800, loss: 0.40130464658141135
iter:  13900, loss: 0.39997156858444216
iter:  14000, loss: 0.3786699564754963
iter:  14100, loss: 0.40541058018803594
iter:  14200, loss: 0.3613242293894291
iter:  14300, loss: 0.3790712596476078
iter:  14400, loss: 0.3848174458742142
iter:  14500, loss: 0.374101425409317
iter:  14600, loss: 0.3746312727034092
iter:  14700, loss: 0.3805694940686226
iter:  14800, loss: 0.3895815275609493
iter:  14900, loss: 0.3722532804310322
iter:  15000, loss: 0.3566392816603184
iter:  15100, loss: 0.33221356227993964
iter:  15200, loss: 0.33420058637857436
iter:  15300, loss: 0.3279283267259598
iter:  15400, loss: 0.3127527305483818
iter:  15500, loss: 0.33714987948536873
iter:  15600, loss: 0.32135466039180755
iter:  15700, loss: 0.3001798834651709
iter:  15800, loss: 0.30287460923194887
iter:  15900, loss: 0.29455108717083933
iter:  16000, loss: 0.31387009620666506
iter:  16100, loss: 0.29221069425344465
iter:  16200, loss: 0.3114088159427047
iter:  16300, loss: 0.2999693224579096
iter:  16400, loss: 0.29659766182303426
iter:  16500, loss: 0.2900066899508238
iter:  16600, loss: 0.2845957112312317
iter:  16700, loss: 0.30361141979694367
iter:  16800, loss: 0.28448720581829545
iter:  16900, loss: 0.29691230654716494
iter:  17000, loss: 0.2799038987606764
iter:  17100, loss: 0.3143535176664591
iter:  17200, loss: 0.2863743954896927
iter:  17300, loss: 0.29100801967084405
iter:  17400, loss: 0.2816260212659836
iter:  17500, loss: 0.2815631263703108
iter:  17600, loss: 0.29673173345625403
iter:  17700, loss: 0.2720735805481672
iter:  17800, loss: 0.2758227102458477
iter:  17900, loss: 0.2730842663347721
iter:  18000, loss: 0.2819295972585678
iter:  18100, loss: 0.2810326057672501
iter:  18200, loss: 0.27671843603253365
iter:  18300, loss: 0.27295941129326823
iter:  18400, loss: 0.2611840870976448
iter:  18500, loss: 0.27505161896348
iter:  18600, loss: 0.27165873505175114
iter:  18700, loss: 0.27539212323725226
iter:  18800, loss: 0.29831088684499263
iter:  18900, loss: 0.24600460156798362
iter:  19000, loss: 0.26822990462183954
iter:  19100, loss: 0.2631078111380339
iter:  19200, loss: 0.28216117903590204
iter:  19300, loss: 0.26966522097587586
iter:  19400, loss: 0.27948681339621545
iter:  19500, loss: 0.2697050048410892
iter:  19600, loss: 0.26980841666460037
iter:  19700, loss: 0.2537428484857082
iter:  19800, loss: 0.24604371331632138
iter:  19900, loss: 0.27868676871061326
iter:  20000, loss: 0.27487227607518433
iter:  20100, loss: 0.2568138461560011
iter:  20200, loss: 0.2567614333331585
iter:  20300, loss: 0.26412384763360025
iter:  20400, loss: 0.2618307126313448
iter:  20500, loss: 0.2451957918331027
iter:  20600, loss: 0.24395348981022835
iter:  20700, loss: 0.2500130263715982
iter:  20800, loss: 0.24526065342128278
iter:  20900, loss: 0.24742558732628822
iter:  21000, loss: 0.24585301384329797
iter:  21100, loss: 0.2299562906473875
iter:  21200, loss: 0.2535651148855686
iter:  21300, loss: 0.23183813653886318
iter:  21400, loss: 0.23918257430195808
iter:  21500, loss: 0.2288723485916853
iter:  21600, loss: 0.25962606437504293
iter:  21700, loss: 0.2435444512218237
iter:  21800, loss: 0.24160354517400265
iter:  21900, loss: 0.22808887980878353
iter:  22000, loss: 0.2289252408221364
iter:  22100, loss: 0.2481565000861883
iter:  22200, loss: 0.23826927967369557
iter:  22300, loss: 0.23840596169233322
iter:  22400, loss: 0.23266201220452787
iter:  22500, loss: 0.2306913712620735
iter:  22600, loss: 0.24082069810479878
iter:  22700, loss: 0.2317061211168766
iter:  22800, loss: 0.2413235890865326
iter:  22900, loss: 0.21276819601655006
iter:  23000, loss: 0.2564593444019556
iter:  23100, loss: 0.2273196068406105
iter:  23200, loss: 0.23088292919099332
iter:  23300, loss: 0.23060130663216113
iter:  23400, loss: 0.23025838904082774
iter:  23500, loss: 0.22997308634221553
iter:  23600, loss: 0.23316305503249168
iter:  23700, loss: 0.2307479937374592
iter:  23800, loss: 0.2433027135580778
iter:  23900, loss: 0.22901961110532285
iter:  24000, loss: 0.23698407359421253
iter:  24100, loss: 0.2276777794957161
iter:  24200, loss: 0.24418692871928216
iter:  24300, loss: 0.23281091801822185
iter:  24400, loss: 0.22483400776982307
iter:  24500, loss: 0.22366790138185025
iter:  24600, loss: 0.24500219322741032
iter:  24700, loss: 0.23454473234713077
iter:  24800, loss: 0.22931907400488855
iter:  24900, loss: 0.2306350565329194
iter:  25000, loss: 0.23999262146651745
iter:  25100, loss: 0.22452490843832493
iter:  25200, loss: 0.2072774025797844
iter:  25300, loss: 0.22115893617272378
iter:  25400, loss: 0.24363386638462545
iter:  25500, loss: 0.2081291201338172
iter:  25600, loss: 0.2265640852600336
iter:  25700, loss: 0.23587699614465238
iter:  25800, loss: 0.21986399453133346
iter:  25900, loss: 0.2246007738262415
iter:  26000, loss: 0.23648374095559122
iter:  26100, loss: 0.22359740249812604
iter:  26200, loss: 0.22417713031172753
iter:  26300, loss: 0.21795401215553284
iter:  26400, loss: 0.2217384084314108
iter:  26500, loss: 0.2145292641967535
iter:  26600, loss: 0.2327584996074438
iter:  26700, loss: 0.2201703979820013
iter:  26800, loss: 0.21485175795853137
iter:  26900, loss: 0.23147274214774372
iter:  27000, loss: 0.21478984668850898
iter:  27100, loss: 0.21871273815631867
iter:  27200, loss: 0.22402992799878121
iter:  27300, loss: 0.22151158705353738
iter:  27400, loss: 0.22979805715382098
iter:  27500, loss: 0.2246239782124758
iter:  27600, loss: 0.2235701061785221
iter:  27700, loss: 0.21980936765670778
iter:  27800, loss: 0.229628129824996
iter:  27900, loss: 0.22233021296560765
iter:  28000, loss: 0.21566987909376623
iter:  28100, loss: 0.22674679443240164
iter:  28200, loss: 0.22870813831686973
iter:  28300, loss: 0.21674789048731327
iter:  28400, loss: 0.21968309029936792
iter:  28500, loss: 0.2122025291621685
iter:  28600, loss: 0.21490467205643654
iter:  28700, loss: 0.21448486626148225
iter:  28800, loss: 0.23338743716478347
iter:  28900, loss: 0.22947184331715106
iter:  29000, loss: 0.24829865969717502
iter:  29100, loss: 0.21979642599821092
iter:  29200, loss: 0.21862659998238088
iter:  29300, loss: 0.21102990910410882
iter:  29400, loss: 0.23346387095749377
iter:  29500, loss: 0.2313929032534361
iter:  29600, loss: 0.2159725771844387
iter:  29700, loss: 0.21662115193903447
iter:  29800, loss: 0.21811173044145107
iter:  29900, loss: 0.2059375248476863
iter:  30000, loss: 0.21716466993093492
iter:  30100, loss: 0.23731149569153787
iter:  30200, loss: 0.2212904142588377
iter:  30300, loss: 0.22548204585909842
iter:  30400, loss: 0.22229713186621666
iter:  30500, loss: 0.22447300247848034
iter:  30600, loss: 0.22972967207431794
iter:  30700, loss: 0.22800377659499646
iter:  30800, loss: 0.2089315876364708
iter:  30900, loss: 0.20292263656854628
iter:  31000, loss: 0.22387992426753045
iter:  31100, loss: 0.23136712290346623
iter:  31200, loss: 0.22116009049117566
iter:  31300, loss: 0.22161328673362732
iter:  31400, loss: 0.21310439988970756
iter:  31500, loss: 0.23576088137924672
iter:  31600, loss: 0.2262596120685339
iter:  31700, loss: 0.21010553762316703
iter:  31800, loss: 0.22031964585185052
iter:  31900, loss: 0.21903710622340442
iter:  32000, loss: 0.2259364964812994

The final accuracy is: 87.7
The final error is: 12.3
correct ratio is: 0.877
