Namespace(batch=64, timestamp='0406172725', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='Adam', lr=0.1, momentum=0.9, weight_decay=0.0001, decay_step=5000, lr_decay_rate=0.2, num_iter=32000)

The total number of parameter is: 4.884 M
iter:    100, loss: 2.782665817737579
iter:    200, loss: 2.2560082840919495
iter:    300, loss: 2.0643121397495268
iter:    400, loss: 1.9974674344062806
iter:    500, loss: 1.982657264471054
iter:    600, loss: 1.9698231041431427
iter:    700, loss: 1.9572305715084075
iter:    800, loss: 1.9619892311096192
iter:    900, loss: 1.9649772143363953
iter:   1000, loss: 1.9522307777404786
iter:   1100, loss: 1.9484424459934235
iter:   1200, loss: 1.94934743642807
iter:   1300, loss: 1.9418419182300568
iter:   1400, loss: 1.9523039603233336
iter:   1500, loss: 1.9531972646713256
iter:   1600, loss: 1.9543319511413575
iter:   1700, loss: 1.95006658911705
iter:   1800, loss: 1.9386812579631805
iter:   1900, loss: 1.9449917566776276
iter:   2000, loss: 1.9480847060680389
iter:   2100, loss: 1.9490569293498994
iter:   2200, loss: 1.945830523967743
iter:   2300, loss: 1.9654157292842864
iter:   2400, loss: 1.9280717635154725
iter:   2500, loss: 1.9187796437740325
iter:   2600, loss: 1.9688399827480316
iter:   2700, loss: 1.9515437507629394
iter:   2800, loss: 1.9458222675323487
iter:   2900, loss: 1.9331435644626618
iter:   3000, loss: 1.932726047039032
iter:   3100, loss: 1.9550107276439668
iter:   3200, loss: 1.9527709662914277
iter:   3300, loss: 1.9488014590740204
iter:   3400, loss: 1.9602251470088958
iter:   3500, loss: 1.9344162654876709
iter:   3600, loss: 1.9333580946922302
iter:   3700, loss: 1.9273060500621795
iter:   3800, loss: 1.9601763713359832
iter:   3900, loss: 1.9477178299427031
iter:   4000, loss: 1.9477148354053497
iter:   4100, loss: 2.000309692621231
iter:   4200, loss: 1.9543261098861695
iter:   4300, loss: 1.9464919543266297
iter:   4400, loss: 1.9884894120693206
iter:   4500, loss: 1.9511880147457124
iter:   4600, loss: 1.9654210889339447
iter:   4700, loss: 1.9419092428684235
iter:   4800, loss: 1.961056672334671
iter:   4900, loss: 1.947018882036209
iter:   5000, loss: 1.9288452136516572
iter:   5100, loss: 1.8785881364345551
iter:   5200, loss: 1.8510549533367158
iter:   5300, loss: 1.8403478538990021
iter:   5400, loss: 1.8501485455036164
iter:   5500, loss: 1.8382157695293426
iter:   5600, loss: 1.8321768724918366
iter:   5700, loss: 1.8312440860271453
iter:   5800, loss: 1.8216906654834748
iter:   5900, loss: 1.8228467571735383
iter:   6000, loss: 1.8398867058753967
iter:   6100, loss: 1.8272796487808227
iter:   6200, loss: 1.8115780520439149
iter:   6300, loss: 1.811894906759262
iter:   6400, loss: 1.7963214349746703
iter:   6500, loss: 1.8099788284301759
iter:   6600, loss: 1.8023867845535277
iter:   6700, loss: 1.7922514843940736
iter:   6800, loss: 1.7946672677993774
iter:   6900, loss: 1.7768235075473786
iter:   7000, loss: 1.743171328306198
iter:   7100, loss: 1.7533429527282716
iter:   7200, loss: 1.7452173221111298
iter:   7300, loss: 1.7370396554470062
iter:   7400, loss: 1.7032004034519195
iter:   7500, loss: 1.6932580530643464
iter:   7600, loss: 1.6721750569343568
iter:   7700, loss: 1.675330389738083
iter:   7800, loss: 1.6679212188720702
iter:   7900, loss: 1.690702316761017
iter:   8000, loss: 1.6613103818893433
iter:   8100, loss: 1.6553597640991211
iter:   8200, loss: 1.6627376234531404
iter:   8300, loss: 1.6562851810455321
iter:   8400, loss: 1.6433284091949463
iter:   8500, loss: 1.634085305929184
iter:   8600, loss: 1.6505481016635895
iter:   8700, loss: 1.6519854414463042
iter:   8800, loss: 1.6417374217510223
iter:   8900, loss: 1.6572773087024688
iter:   9000, loss: 1.6189435935020446
iter:   9100, loss: 1.610343862771988
iter:   9200, loss: 1.6283962988853455
iter:   9300, loss: 1.641715224981308
iter:   9400, loss: 1.6179987263679505
iter:   9500, loss: 1.6386280500888823
iter:   9600, loss: 1.6075416457653047
iter:   9700, loss: 1.6227519261837005
iter:   9800, loss: 1.593475856781006
iter:   9900, loss: 1.61142653465271
iter:  10000, loss: 1.6000729715824127
iter:  10100, loss: 1.5431649219989776
iter:  10200, loss: 1.5569308185577393
iter:  10300, loss: 1.5291488981246948
iter:  10400, loss: 1.5354083156585694
iter:  10500, loss: 1.5377954304218293
iter:  10600, loss: 1.497285703420639
iter:  10700, loss: 1.518066989183426
iter:  10800, loss: 1.505540862083435
iter:  10900, loss: 1.5072241961956023
iter:  11000, loss: 1.4970758211612702
iter:  11100, loss: 1.4958103394508362
iter:  11200, loss: 1.4900225114822387
iter:  11300, loss: 1.4573995292186737
iter:  11400, loss: 1.4784912538528443
iter:  11500, loss: 1.469377360343933
iter:  11600, loss: 1.471447721719742
iter:  11700, loss: 1.4438969659805299
iter:  11800, loss: 1.435635666847229
iter:  11900, loss: 1.4137648034095764
iter:  12000, loss: 1.418212548494339
iter:  12100, loss: 1.4265833854675294
iter:  12200, loss: 1.4220195317268371
iter:  12300, loss: 1.4212772512435914
iter:  12400, loss: 1.3989603972434999
iter:  12500, loss: 1.4055991935729981
iter:  12600, loss: 1.3870468497276307
iter:  12700, loss: 1.3702009415626526
iter:  12800, loss: 1.3995433020591737
iter:  12900, loss: 1.367483206987381
iter:  13000, loss: 1.393792700767517
iter:  13100, loss: 1.391196676492691
iter:  13200, loss: 1.3589319837093354
iter:  13300, loss: 1.3697928822040557
iter:  13400, loss: 1.3717166805267333
iter:  13500, loss: 1.35941309094429
iter:  13600, loss: 1.3733896791934967
iter:  13700, loss: 1.3446674305200577
iter:  13800, loss: 1.347635852098465
iter:  13900, loss: 1.3649891245365142
iter:  14000, loss: 1.3493777239322662
iter:  14100, loss: 1.3464749550819397
iter:  14200, loss: 1.355240051150322
iter:  14300, loss: 1.3618329167366028
iter:  14400, loss: 1.3319554340839386
iter:  14500, loss: 1.3111966669559478
iter:  14600, loss: 1.3404129981994628
iter:  14700, loss: 1.3078239619731904
iter:  14800, loss: 1.3123455905914307
iter:  14900, loss: 1.2922032570838928
iter:  15000, loss: 1.3135569393634796
iter:  15100, loss: 1.2796813905239106
iter:  15200, loss: 1.2631218886375428
iter:  15300, loss: 1.2500701147317885
iter:  15400, loss: 1.251138109564781
iter:  15500, loss: 1.2838894641399383
iter:  15600, loss: 1.2547923392057418
iter:  15700, loss: 1.2720238554477692
iter:  15800, loss: 1.271039160490036
iter:  15900, loss: 1.2698561179637908
iter:  16000, loss: 1.2450020653009415
iter:  16100, loss: 1.2569332885742188
iter:  16200, loss: 1.238758423924446
iter:  16300, loss: 1.245089277625084
iter:  16400, loss: 1.2576655292510985
iter:  16500, loss: 1.269530371427536
iter:  16600, loss: 1.227910828590393
iter:  16700, loss: 1.2521404963731766
iter:  16800, loss: 1.2394429272413254
iter:  16900, loss: 1.2255891400575638
iter:  17000, loss: 1.2536102682352066
iter:  17100, loss: 1.2359790414571763
iter:  17200, loss: 1.2534540450572969
iter:  17300, loss: 1.2401843452453614
iter:  17400, loss: 1.2434802490472794
iter:  17500, loss: 1.2455145978927613
iter:  17600, loss: 1.2262591767311095
iter:  17700, loss: 1.2478999119997025
iter:  17800, loss: 1.2106913560628891
iter:  17900, loss: 1.247041935324669
iter:  18000, loss: 1.2242396360635757
iter:  18100, loss: 1.242870677113533
iter:  18200, loss: 1.2445360320806502
iter:  18300, loss: 1.2286986488103866
iter:  18400, loss: 1.2202217346429824
iter:  18500, loss: 1.2275489002466202
iter:  18600, loss: 1.2313207578659058
iter:  18700, loss: 1.2184418374300003
iter:  18800, loss: 1.2166387087106705
iter:  18900, loss: 1.2406307512521744
iter:  19000, loss: 1.2285513710975646
iter:  19100, loss: 1.2262633848190307
iter:  19200, loss: 1.2141950988769532
iter:  19300, loss: 1.2113157188892365
iter:  19400, loss: 1.2017866837978364
iter:  19500, loss: 1.2289742535352708
iter:  19600, loss: 1.2125015956163407
iter:  19700, loss: 1.2190682899951935
iter:  19800, loss: 1.1905151683092117
iter:  19900, loss: 1.1925783616304397
iter:  20000, loss: 1.1988529032468795
iter:  20100, loss: 1.1941814762353897
iter:  20200, loss: 1.2134773534536363
iter:  20300, loss: 1.1845566630363464
iter:  20400, loss: 1.1892272067070007
iter:  20500, loss: 1.186110525727272
iter:  20600, loss: 1.1947184526920318
iter:  20700, loss: 1.1572124755382538
iter:  20800, loss: 1.1911366200447082
iter:  20900, loss: 1.1815713053941728
iter:  21000, loss: 1.193723902106285
iter:  21100, loss: 1.1725191336870193
iter:  21200, loss: 1.1846194595098496
iter:  21300, loss: 1.2082977432012558
iter:  21400, loss: 1.1989941990375519
iter:  21500, loss: 1.1776562762260436
iter:  21600, loss: 1.1893198668956757
iter:  21700, loss: 1.188658550977707
iter:  21800, loss: 1.1888971161842345
iter:  21900, loss: 1.1607622295618056
iter:  22000, loss: 1.1754770058393478
iter:  22100, loss: 1.2011490887403489
iter:  22200, loss: 1.1720732533931733
iter:  22300, loss: 1.1904539561271668
iter:  22400, loss: 1.1524673348665238
iter:  22500, loss: 1.171238163113594
iter:  22600, loss: 1.1738795775175095
iter:  22700, loss: 1.1542935985326768
iter:  22800, loss: 1.1881307131052017
iter:  22900, loss: 1.185078468322754
iter:  23000, loss: 1.1634198868274688
iter:  23100, loss: 1.1497150492668151
iter:  23200, loss: 1.1711223328113556
iter:  23300, loss: 1.1745173025131226
iter:  23400, loss: 1.1730263942480088
iter:  23500, loss: 1.1554056018590928
iter:  23600, loss: 1.1775257021188736
iter:  23700, loss: 1.1738373547792436
iter:  23800, loss: 1.1756658726930618
iter:  23900, loss: 1.1606233990192414
iter:  24000, loss: 1.1401172822713852
iter:  24100, loss: 1.1552444279193879
iter:  24200, loss: 1.1814437365531922
iter:  24300, loss: 1.172407728433609
iter:  24400, loss: 1.160733887553215
iter:  24500, loss: 1.1575701075792313
iter:  24600, loss: 1.1528853285312652
iter:  24700, loss: 1.1651311028003692
iter:  24800, loss: 1.1596881651878357
iter:  24900, loss: 1.1730834126472474
iter:  25000, loss: 1.1496222305297852
iter:  25100, loss: 1.187342336177826
iter:  25200, loss: 1.1536486965417863
iter:  25300, loss: 1.164392228126526
iter:  25400, loss: 1.1502041399478913
iter:  25500, loss: 1.1461703312397002
iter:  25600, loss: 1.1421061301231383
iter:  25700, loss: 1.1515974098443984
iter:  25800, loss: 1.128257600069046
iter:  25900, loss: 1.146482414007187
iter:  26000, loss: 1.1423600500822066
iter:  26100, loss: 1.154549282193184
iter:  26200, loss: 1.1545131081342697
iter:  26300, loss: 1.1342214584350585
iter:  26400, loss: 1.150186586380005
iter:  26500, loss: 1.1606631296873093
iter:  26600, loss: 1.153687411546707
iter:  26700, loss: 1.1375159704685212
iter:  26800, loss: 1.1593072998523712
iter:  26900, loss: 1.1313201385736464
iter:  27000, loss: 1.147575997710228
iter:  27100, loss: 1.1526039069890976
iter:  27200, loss: 1.1666808551549912
iter:  27300, loss: 1.1418666863441467
iter:  27400, loss: 1.13419049680233
iter:  27500, loss: 1.1529704970121384
iter:  27600, loss: 1.1375696468353271
iter:  27700, loss: 1.156206066608429
iter:  27800, loss: 1.1599892783164978
iter:  27900, loss: 1.128045135140419
iter:  28000, loss: 1.1448253172636031
iter:  28100, loss: 1.1483191150426864
iter:  28200, loss: 1.158299258351326
iter:  28300, loss: 1.130198734998703
iter:  28400, loss: 1.1347076773643494
iter:  28500, loss: 1.1659808486700058
iter:  28600, loss: 1.1409825766086579
iter:  28700, loss: 1.1590289354324341
iter:  28800, loss: 1.1378804218769074
iter:  28900, loss: 1.1326575112342834
iter:  29000, loss: 1.154858776330948
iter:  29100, loss: 1.1320276528596878
iter:  29200, loss: 1.1520514571666718
iter:  29300, loss: 1.1357879811525344
iter:  29400, loss: 1.1614638859033584
iter:  29500, loss: 1.1389607417583465
iter:  29600, loss: 1.1340489757061005
iter:  29700, loss: 1.1413550388813019
iter:  29800, loss: 1.1364269268512726
iter:  29900, loss: 1.1298348665237428
iter:  30000, loss: 1.1466288071870805
iter:  30100, loss: 1.1739924973249436
iter:  30200, loss: 1.1353591006994248
iter:  30300, loss: 1.1328486704826355
iter:  30400, loss: 1.1624847757816315
iter:  30500, loss: 1.1273964822292328
iter:  30600, loss: 1.158743107318878
iter:  30700, loss: 1.1496903520822526
iter:  30800, loss: 1.1455867898464203
iter:  30900, loss: 1.128405467271805
iter:  31000, loss: 1.1439604949951172
iter:  31100, loss: 1.140975690484047
iter:  31200, loss: 1.1339568066596986
iter:  31300, loss: 1.1493600809574127
iter:  31400, loss: 1.158859750032425
iter:  31500, loss: 1.1334321284294129
iter:  31600, loss: 1.1391004151105881
iter:  31700, loss: 1.1399263149499894
iter:  31800, loss: 1.1332061684131622
iter:  31900, loss: 1.11316725730896
iter:  32000, loss: 1.120217872262001

The final accuracy is: 60.47
The final error is: 39.53
correct ratio is: 0.605
