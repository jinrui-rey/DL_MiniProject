Namespace(batch=64, timestamp='0406160108', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001, decay_step=5000, lr_decay_rate=0.2, num_iter=32000)

The total number of parameter is: 4.884 M
iter:    100, loss: 2.5117468667030334
iter:    200, loss: 2.024379941225052
iter:    300, loss: 1.9742565727233887
iter:    400, loss: 1.9226460576057434
iter:    500, loss: 1.8412193739414215
iter:    600, loss: 1.7710506463050841
iter:    700, loss: 1.7253215670585633
iter:    800, loss: 1.6731103122234345
iter:    900, loss: 1.623162477016449
iter:   1000, loss: 1.5944839584827424
iter:   1100, loss: 1.5507010233402252
iter:   1200, loss: 1.5371133589744568
iter:   1300, loss: 1.4995363426208497
iter:   1400, loss: 1.4359401178359985
iter:   1500, loss: 1.4418776047229767
iter:   1600, loss: 1.3802129876613618
iter:   1700, loss: 1.3712296724319457
iter:   1800, loss: 1.3421607065200805
iter:   1900, loss: 1.3011643135547637
iter:   2000, loss: 1.26787812769413
iter:   2100, loss: 1.2850548708438874
iter:   2200, loss: 1.1983157676458358
iter:   2300, loss: 1.1770267510414123
iter:   2400, loss: 1.1709860306978226
iter:   2500, loss: 1.103066422343254
iter:   2600, loss: 1.0954195606708526
iter:   2700, loss: 1.0840006828308106
iter:   2800, loss: 1.0454014015197755
iter:   2900, loss: 0.993575993180275
iter:   3000, loss: 1.0045282918214797
iter:   3100, loss: 0.9615329432487488
iter:   3200, loss: 0.9502184677124024
iter:   3300, loss: 0.9217727482318878
iter:   3400, loss: 0.9313514214754105
iter:   3500, loss: 0.8918659895658493
iter:   3600, loss: 0.8623882728815079
iter:   3700, loss: 0.8704556328058243
iter:   3800, loss: 0.8256278449296951
iter:   3900, loss: 0.8364911764860153
iter:   4000, loss: 0.7862896525859833
iter:   4100, loss: 0.7788573387265205
iter:   4200, loss: 0.7487259796261787
iter:   4300, loss: 0.7886222457885742
iter:   4400, loss: 0.7485848069190979
iter:   4500, loss: 0.7414466878771782
iter:   4600, loss: 0.6993514153361321
iter:   4700, loss: 0.7164400777220726
iter:   4800, loss: 0.6775081181526184
iter:   4900, loss: 0.6767627692222595
iter:   5000, loss: 0.6657249772548676
iter:   5100, loss: 0.6034442543983459
iter:   5200, loss: 0.5322412759065628
iter:   5300, loss: 0.5546465763449668
iter:   5400, loss: 0.5075058603286743
iter:   5500, loss: 0.5211713629961013
iter:   5600, loss: 0.49663959324359896
iter:   5700, loss: 0.49760815739631653
iter:   5800, loss: 0.49981027498841285
iter:   5900, loss: 0.4863837370276451
iter:   6000, loss: 0.46826383501291274
iter:   6100, loss: 0.4799301178753376
iter:   6200, loss: 0.47278414994478224
iter:   6300, loss: 0.4556056955456734
iter:   6400, loss: 0.45721671134233477
iter:   6500, loss: 0.4472928237915039
iter:   6600, loss: 0.4506594632565975
iter:   6700, loss: 0.4532406722009182
iter:   6800, loss: 0.4356055682897568
iter:   6900, loss: 0.4449487233161926
iter:   7000, loss: 0.4570414717495441
iter:   7100, loss: 0.42439546570181846
iter:   7200, loss: 0.4314337877929211
iter:   7300, loss: 0.4143191108107567
iter:   7400, loss: 0.42490721240639684
iter:   7500, loss: 0.4340635184943676
iter:   7600, loss: 0.42855786070227625
iter:   7700, loss: 0.42315503254532816
iter:   7800, loss: 0.4213057790696621
iter:   7900, loss: 0.40297124072909357
iter:   8000, loss: 0.40827907726168633
iter:   8100, loss: 0.41473937578499315
iter:   8200, loss: 0.39443399727344514
iter:   8300, loss: 0.41155950248241424
iter:   8400, loss: 0.42047314539551733
iter:   8500, loss: 0.41030140340328214
iter:   8600, loss: 0.37928122505545614
iter:   8700, loss: 0.37888813510537145
iter:   8800, loss: 0.38134857282042506
iter:   8900, loss: 0.3759783262014389
iter:   9000, loss: 0.39111670970916745
iter:   9100, loss: 0.3838520886003971
iter:   9200, loss: 0.36961933255195617
iter:   9300, loss: 0.37915161475539205
iter:   9400, loss: 0.3781724140048027
iter:   9500, loss: 0.3790618123114109
iter:   9600, loss: 0.36598976328969
iter:   9700, loss: 0.366849514991045
iter:   9800, loss: 0.3728679992258549
iter:   9900, loss: 0.3486862812936306
iter:  10000, loss: 0.3677178679406643
iter:  10100, loss: 0.3410769647359848
iter:  10200, loss: 0.326191880479455
iter:  10300, loss: 0.31222503647208216
iter:  10400, loss: 0.28793934240937236
iter:  10500, loss: 0.29807805389165876
iter:  10600, loss: 0.2866302461922169
iter:  10700, loss: 0.3037775791436434
iter:  10800, loss: 0.28324635319411756
iter:  10900, loss: 0.29084452480077744
iter:  11000, loss: 0.28028986617922785
iter:  11100, loss: 0.28319432109594345
iter:  11200, loss: 0.2710141138732433
iter:  11300, loss: 0.28706966422498226
iter:  11400, loss: 0.28059982404112815
iter:  11500, loss: 0.27682799495756627
iter:  11600, loss: 0.27494019374251366
iter:  11700, loss: 0.2652877864986658
iter:  11800, loss: 0.24079996675252915
iter:  11900, loss: 0.25905946515500544
iter:  12000, loss: 0.26555757626891136
iter:  12100, loss: 0.2639273611456156
iter:  12200, loss: 0.27729674741625787
iter:  12300, loss: 0.2752361158281565
iter:  12400, loss: 0.26128856867551803
iter:  12500, loss: 0.26440427646040915
iter:  12600, loss: 0.2629262667894363
iter:  12700, loss: 0.2512898849695921
iter:  12800, loss: 0.2555950490385294
iter:  12900, loss: 0.2556217472627759
iter:  13000, loss: 0.26513312123715876
iter:  13100, loss: 0.2571554896980524
iter:  13200, loss: 0.2475514078885317
iter:  13300, loss: 0.26252929292619226
iter:  13400, loss: 0.23964913193136453
iter:  13500, loss: 0.24699346266686917
iter:  13600, loss: 0.25785490572452546
iter:  13700, loss: 0.25244771026074886
iter:  13800, loss: 0.2744414345920086
iter:  13900, loss: 0.2431375925242901
iter:  14000, loss: 0.25185513369739054
iter:  14100, loss: 0.2562096371501684
iter:  14200, loss: 0.23709433533251287
iter:  14300, loss: 0.24401791349053384
iter:  14400, loss: 0.25494264826178553
iter:  14500, loss: 0.23989794604480266
iter:  14600, loss: 0.24829268246889113
iter:  14700, loss: 0.24585308618843554
iter:  14800, loss: 0.24056714445352553
iter:  14900, loss: 0.23466627478599547
iter:  15000, loss: 0.21408255845308305
iter:  15100, loss: 0.2280731574445963
iter:  15200, loss: 0.2331137438863516
iter:  15300, loss: 0.2216723806783557
iter:  15400, loss: 0.22567019566893579
iter:  15500, loss: 0.22213568150997162
iter:  15600, loss: 0.21361768148839475
iter:  15700, loss: 0.20213097620755435
iter:  15800, loss: 0.21055673465132713
iter:  15900, loss: 0.21155916176736356
iter:  16000, loss: 0.21907155148684979
iter:  16100, loss: 0.2146603438258171
iter:  16200, loss: 0.21430429473519325
iter:  16300, loss: 0.21082489907741547
iter:  16400, loss: 0.22574760653078557
iter:  16500, loss: 0.2109623033925891
iter:  16600, loss: 0.21886477880179883
iter:  16700, loss: 0.2012810467928648
iter:  16800, loss: 0.21122064866125584
iter:  16900, loss: 0.19865538995712995
iter:  17000, loss: 0.2084748459607363
iter:  17100, loss: 0.2127745668590069
iter:  17200, loss: 0.21436518516391515
iter:  17300, loss: 0.22003093734383583
iter:  17400, loss: 0.1947445984184742
iter:  17500, loss: 0.1990540435910225
iter:  17600, loss: 0.20030531343072652
iter:  17700, loss: 0.21036380387842654
iter:  17800, loss: 0.20979699529707432
iter:  17900, loss: 0.19484484046697617
iter:  18000, loss: 0.21710450127720832
iter:  18100, loss: 0.21520605593919753
iter:  18200, loss: 0.1953701126202941
iter:  18300, loss: 0.21501638673245907
iter:  18400, loss: 0.21485174398869275
iter:  18500, loss: 0.21440329428762198
iter:  18600, loss: 0.19492619555443524
iter:  18700, loss: 0.1992111711576581
iter:  18800, loss: 0.18958159029483795
iter:  18900, loss: 0.1926692185550928
iter:  19000, loss: 0.20504332412034273
iter:  19100, loss: 0.19535924803465604
iter:  19200, loss: 0.1917959314212203
iter:  19300, loss: 0.2052699249982834
iter:  19400, loss: 0.2079202225059271
iter:  19500, loss: 0.2035704814642668
iter:  19600, loss: 0.2059295442700386
iter:  19700, loss: 0.20385273583233357
iter:  19800, loss: 0.19414834048599006
iter:  19900, loss: 0.208445975035429
iter:  20000, loss: 0.19331648342311383
iter:  20100, loss: 0.20480097576975823
iter:  20200, loss: 0.20573697000741958
iter:  20300, loss: 0.1990141550824046
iter:  20400, loss: 0.19108562286943198
iter:  20500, loss: 0.20493682637810706
iter:  20600, loss: 0.19542911015450953
iter:  20700, loss: 0.1827235622704029
iter:  20800, loss: 0.18055000767111778
iter:  20900, loss: 0.21116802096366882
iter:  21000, loss: 0.19467973604798317
iter:  21100, loss: 0.1904207256808877
iter:  21200, loss: 0.18706303425133228
iter:  21300, loss: 0.19167720064520835
iter:  21400, loss: 0.18766741506755352
iter:  21500, loss: 0.19655376307666303
iter:  21600, loss: 0.20517017561942338
iter:  21700, loss: 0.19029713921248914
iter:  21800, loss: 0.1892560164630413
iter:  21900, loss: 0.18504169519990682
iter:  22000, loss: 0.19735217358916998
iter:  22100, loss: 0.20520578976720572
iter:  22200, loss: 0.18893111631274223
iter:  22300, loss: 0.18318137347698213
iter:  22400, loss: 0.18667463704943657
iter:  22500, loss: 0.20043003410100937
iter:  22600, loss: 0.2031761833280325
iter:  22700, loss: 0.19124294210225343
iter:  22800, loss: 0.20092605032026767
iter:  22900, loss: 0.19038150768727063
iter:  23000, loss: 0.1911367241293192
iter:  23100, loss: 0.18828634437173605
iter:  23200, loss: 0.1872066329419613
iter:  23300, loss: 0.1942874914780259
iter:  23400, loss: 0.1939110676944256
iter:  23500, loss: 0.20821961179375648
iter:  23600, loss: 0.19907159633934499
iter:  23700, loss: 0.19058696031570435
iter:  23800, loss: 0.19785536207258703
iter:  23900, loss: 0.1926126277819276
iter:  24000, loss: 0.19334426879882813
iter:  24100, loss: 0.1908885306492448
iter:  24200, loss: 0.17525483384728432
iter:  24300, loss: 0.1873831870034337
iter:  24400, loss: 0.18845266472548247
iter:  24500, loss: 0.19825975134968757
iter:  24600, loss: 0.1883114593476057
iter:  24700, loss: 0.18766217719763517
iter:  24800, loss: 0.20862823240458966
iter:  24900, loss: 0.19077634774148464
iter:  25000, loss: 0.17943146415054798
iter:  25100, loss: 0.18638786319643258
iter:  25200, loss: 0.17991122078150512
iter:  25300, loss: 0.190348940230906
iter:  25400, loss: 0.1880555285513401
iter:  25500, loss: 0.17952320024371146
iter:  25600, loss: 0.1946308111399412
iter:  25700, loss: 0.18418498370796443
iter:  25800, loss: 0.20617652215063573
iter:  25900, loss: 0.19413043688982726
iter:  26000, loss: 0.1825537856668234
iter:  26100, loss: 0.19375804252922535
iter:  26200, loss: 0.1907458897680044
iter:  26300, loss: 0.19249083496630193
iter:  26400, loss: 0.19749112337827682
iter:  26500, loss: 0.18935306005179883
iter:  26600, loss: 0.19112919960170985
iter:  26700, loss: 0.18906513787806034
iter:  26800, loss: 0.19302062451839447
iter:  26900, loss: 0.18808400429785252
iter:  27000, loss: 0.18811092995107173
iter:  27100, loss: 0.20296001728624105
iter:  27200, loss: 0.1803450619801879
iter:  27300, loss: 0.1881328434869647
iter:  27400, loss: 0.19242247231304646
iter:  27500, loss: 0.1875666443631053
iter:  27600, loss: 0.19003932934254408
iter:  27700, loss: 0.19263979610055684
iter:  27800, loss: 0.18901493519544602
iter:  27900, loss: 0.18320133935660124
iter:  28000, loss: 0.1917095073312521
iter:  28100, loss: 0.19696216221898794
iter:  28200, loss: 0.1882197106257081
iter:  28300, loss: 0.1970754922926426
iter:  28400, loss: 0.1680706512928009
iter:  28500, loss: 0.19449431594461203
iter:  28600, loss: 0.18461105458438395
iter:  28700, loss: 0.19871081590652465
iter:  28800, loss: 0.1817530643939972
iter:  28900, loss: 0.1946430952474475
iter:  29000, loss: 0.19251827787607909
iter:  29100, loss: 0.18991118032485246
iter:  29200, loss: 0.1899933508783579
iter:  29300, loss: 0.18765979394316673
iter:  29400, loss: 0.1944526121765375
iter:  29500, loss: 0.1927336420863867
iter:  29600, loss: 0.19096870496869087
iter:  29700, loss: 0.202899899110198
iter:  29800, loss: 0.1753778398782015
iter:  29900, loss: 0.1929542311653495
iter:  30000, loss: 0.19128536209464073
iter:  30100, loss: 0.18477786660194398
iter:  30200, loss: 0.18367060855031014
iter:  30300, loss: 0.19049312483519315
iter:  30400, loss: 0.193214126303792
iter:  30500, loss: 0.18388181660324335
iter:  30600, loss: 0.17436160173267126
iter:  30700, loss: 0.18953699685633182
iter:  30800, loss: 0.17685968086123466
iter:  30900, loss: 0.1942198771238327
iter:  31000, loss: 0.1967987697944045
iter:  31100, loss: 0.18909594535827637
iter:  31200, loss: 0.1864516840875149
iter:  31300, loss: 0.19301881678402424
iter:  31400, loss: 0.18716034792363645
iter:  31500, loss: 0.2002050716429949
iter:  31600, loss: 0.18276153855025767
iter:  31700, loss: 0.18873328320682048
iter:  31800, loss: 0.1864080922305584
iter:  31900, loss: 0.18318367131054403
iter:  32000, loss: 0.1869224328920245

The final accuracy is: 88.51
The final error is: 11.49
correct ratio is: 0.885
