Namespace(batch=128, timestamp='0406210323', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='SGD', lr=0.3, momentum=0.9, weight_decay=0.0001, decay_step=4000, lr_decay_rate=0.2, num_iter=32000)

The total number of parameter is: 4.884 M
iter:    100, loss: 2.626868965625763
iter:    200, loss: 2.0798444533348084
iter:    300, loss: 1.9786510014533996
iter:    400, loss: 1.935616124868393
iter:    500, loss: 1.899388828277588
iter:    600, loss: 1.8725830233097076
iter:    700, loss: 1.8321103954315185
iter:    800, loss: 1.7311884152889252
iter:    900, loss: 1.6680252301692962
iter:   1000, loss: 1.5859101295471192
iter:   1100, loss: 1.5108708703517915
iter:   1200, loss: 1.467578377723694
iter:   1300, loss: 1.396449204683304
iter:   1400, loss: 1.3664306020736694
iter:   1500, loss: 1.3055555832386017
iter:   1600, loss: 1.2557462501525878
iter:   1700, loss: 1.224571703672409
iter:   1800, loss: 1.1616605812311172
iter:   1900, loss: 1.1109140169620515
iter:   2000, loss: 1.0806753545999528
iter:   2100, loss: 1.0508799815177918
iter:   2200, loss: 1.0219680166244507
iter:   2300, loss: 0.9989880347251892
iter:   2400, loss: 0.9629600816965103
iter:   2500, loss: 0.9140072685480117
iter:   2600, loss: 0.9002859753370285
iter:   2700, loss: 0.881729183793068
iter:   2800, loss: 0.8440586721897125
iter:   2900, loss: 0.8038103890419006
iter:   3000, loss: 0.7768564945459366
iter:   3100, loss: 0.778826550245285
iter:   3200, loss: 0.7417919999361038
iter:   3300, loss: 0.7465829074382782
iter:   3400, loss: 0.6928560754656792
iter:   3500, loss: 0.6932089331746102
iter:   3600, loss: 0.6510736027359962
iter:   3700, loss: 0.6683113926649094
iter:   3800, loss: 0.6456449446082115
iter:   3900, loss: 0.6530901208519936
iter:   4000, loss: 0.6107297694683075
iter:   4100, loss: 0.5141671612858772
iter:   4200, loss: 0.4703954204916954
iter:   4300, loss: 0.44608365088701246
iter:   4400, loss: 0.42506353825330734
iter:   4500, loss: 0.4195648866891861
iter:   4600, loss: 0.42909874379634855
iter:   4700, loss: 0.4154099790751934
iter:   4800, loss: 0.38445676043629645
iter:   4900, loss: 0.38952540799975394
iter:   5000, loss: 0.3983055958151817
iter:   5100, loss: 0.4019826889038086
iter:   5200, loss: 0.37098248675465584
iter:   5300, loss: 0.3774879556894302
iter:   5400, loss: 0.3755209709703922
iter:   5500, loss: 0.37225961849093436
iter:   5600, loss: 0.3528113490343094
iter:   5700, loss: 0.3565390844643116
iter:   5800, loss: 0.36295632883906365
iter:   5900, loss: 0.3606034253537655
iter:   6000, loss: 0.3468654794991016
iter:   6100, loss: 0.34290552750229836
iter:   6200, loss: 0.35471771866083146
iter:   6300, loss: 0.33191207945346834
iter:   6400, loss: 0.3266229423880577
iter:   6500, loss: 0.32368594825267794
iter:   6600, loss: 0.33440849334001543
iter:   6700, loss: 0.3201167018711567
iter:   6800, loss: 0.3213994298875332
iter:   6900, loss: 0.31601970255374906
iter:   7000, loss: 0.3173749725520611
iter:   7100, loss: 0.3202292704582214
iter:   7200, loss: 0.30641847506165504
iter:   7300, loss: 0.3104399561882019
iter:   7400, loss: 0.308117388933897
iter:   7500, loss: 0.2756389281153679
iter:   7600, loss: 0.29259149089455605
iter:   7700, loss: 0.31098478883504865
iter:   7800, loss: 0.30244974210858344
iter:   7900, loss: 0.28584490329027173
iter:   8000, loss: 0.28382181584835053
iter:   8100, loss: 0.2515662744641304
iter:   8200, loss: 0.23551507912576197
iter:   8300, loss: 0.20719246089458465
iter:   8400, loss: 0.20055872306227684
iter:   8500, loss: 0.2051227229833603
iter:   8600, loss: 0.1907932411134243
iter:   8700, loss: 0.1854010434448719
iter:   8800, loss: 0.18096708036959172
iter:   8900, loss: 0.17689007118344308
iter:   9000, loss: 0.1971470346301794
iter:   9100, loss: 0.17861956395208836
iter:   9200, loss: 0.17288512006402015
iter:   9300, loss: 0.17847225196659566
iter:   9400, loss: 0.1733671136200428
iter:   9500, loss: 0.17550141036510467
iter:   9600, loss: 0.16363451346755029
iter:   9700, loss: 0.16570743568241597
iter:   9800, loss: 0.1687031514197588
iter:   9900, loss: 0.156995005607605
iter:  10000, loss: 0.1686420164257288
iter:  10100, loss: 0.15675922326743602
iter:  10200, loss: 0.15996892243623734
iter:  10300, loss: 0.14672842301428318
iter:  10400, loss: 0.15775016501545905
iter:  10500, loss: 0.15220998045057058
iter:  10600, loss: 0.1495761600881815
iter:  10700, loss: 0.14267842307686807
iter:  10800, loss: 0.15145686000585556
iter:  10900, loss: 0.1537198796123266
iter:  11000, loss: 0.13705537389963865
iter:  11100, loss: 0.1414974372088909
iter:  11200, loss: 0.13877155117690562
iter:  11300, loss: 0.15060808911919593
iter:  11400, loss: 0.13219113152474166
iter:  11500, loss: 0.12778549440205098
iter:  11600, loss: 0.14319320179522038
iter:  11700, loss: 0.14676939267665148
iter:  11800, loss: 0.1337591815367341
iter:  11900, loss: 0.1213855342194438
iter:  12000, loss: 0.1290902216732502
iter:  12100, loss: 0.11763539575040341
iter:  12200, loss: 0.11275064185261727
iter:  12300, loss: 0.10220468986779452
iter:  12400, loss: 0.09915881656110287
iter:  12500, loss: 0.09825240733101964
iter:  12600, loss: 0.09428914725780486
iter:  12700, loss: 0.09374818503856659
iter:  12800, loss: 0.09573601044714451
iter:  12900, loss: 0.09917667143046856
iter:  13000, loss: 0.09103880262002349
iter:  13100, loss: 0.09328379690647125
iter:  13200, loss: 0.09701646525412798
iter:  13300, loss: 0.09139976523816586
iter:  13400, loss: 0.08529005507007241
iter:  13500, loss: 0.0914807496406138
iter:  13600, loss: 0.07862646263092757
iter:  13700, loss: 0.09070637149736285
iter:  13800, loss: 0.0790329952724278
iter:  13900, loss: 0.08867662370204926
iter:  14000, loss: 0.08528073128312826
iter:  14100, loss: 0.08539162546396256
iter:  14200, loss: 0.07984040645882487
iter:  14300, loss: 0.0882599388435483
iter:  14400, loss: 0.08664226312190294
iter:  14500, loss: 0.08583614656701684
iter:  14600, loss: 0.07849413774907589
iter:  14700, loss: 0.08194572219625115
iter:  14800, loss: 0.08507643304765225
iter:  14900, loss: 0.07521690834313631
iter:  15000, loss: 0.07707282731309534
iter:  15100, loss: 0.07768111193552613
iter:  15200, loss: 0.08121644431725145
iter:  15300, loss: 0.07856094969436526
iter:  15400, loss: 0.07849572122097015
iter:  15500, loss: 0.07661839315667748
iter:  15600, loss: 0.07705427346751094
iter:  15700, loss: 0.07584649089723826
iter:  15800, loss: 0.07280867647379637
iter:  15900, loss: 0.07459893615916371
iter:  16000, loss: 0.07597984937950969
iter:  16100, loss: 0.06736815103329719
iter:  16200, loss: 0.06889115570113064
iter:  16300, loss: 0.06334290029481053
iter:  16400, loss: 0.06985986093059182
iter:  16500, loss: 0.06711793914437295
iter:  16600, loss: 0.06769165094941855
iter:  16700, loss: 0.0692180342786014
iter:  16800, loss: 0.06799142882227897
iter:  16900, loss: 0.06254546031355858
iter:  17000, loss: 0.060608161855489014
iter:  17100, loss: 0.0655156366713345
iter:  17200, loss: 0.06785589590668678
iter:  17300, loss: 0.07041668597608805
iter:  17400, loss: 0.06446294464170933
iter:  17500, loss: 0.06423587255179881
iter:  17600, loss: 0.06607799712568521
iter:  17700, loss: 0.0636702676396817
iter:  17800, loss: 0.06349619379267096
iter:  17900, loss: 0.06189050399698317
iter:  18000, loss: 0.06620030419901013
iter:  18100, loss: 0.06286260448396205
iter:  18200, loss: 0.059673037249594926
iter:  18300, loss: 0.06362888376228511
iter:  18400, loss: 0.06617783199995757
iter:  18500, loss: 0.062226988710463046
iter:  18600, loss: 0.05861762215383351
iter:  18700, loss: 0.06387019511312246
iter:  18800, loss: 0.05997724484652281
iter:  18900, loss: 0.061299533694982526
iter:  19000, loss: 0.0689699068106711
iter:  19100, loss: 0.06201984125189483
iter:  19200, loss: 0.06358104443177581
iter:  19300, loss: 0.06033347442746163
iter:  19400, loss: 0.059567039497196675
iter:  19500, loss: 0.06151673927903176
iter:  19600, loss: 0.06078620394691825
iter:  19700, loss: 0.05908923963084817
iter:  19800, loss: 0.06175271838903427
iter:  19900, loss: 0.06243229546584189
iter:  20000, loss: 0.057520274994894864
iter:  20100, loss: 0.061569483652710914
iter:  20200, loss: 0.058046398451551795
iter:  20300, loss: 0.0632439935952425
iter:  20400, loss: 0.05619049239903688
iter:  20500, loss: 0.05961440656334162
iter:  20600, loss: 0.0611086580902338
iter:  20700, loss: 0.060386882675811646
iter:  20800, loss: 0.06151916854083538
iter:  20900, loss: 0.06218024807982147
iter:  21000, loss: 0.05650281650014222
iter:  21100, loss: 0.060938562136143445
iter:  21200, loss: 0.0574872984457761
iter:  21300, loss: 0.06078700916841626
iter:  21400, loss: 0.06146823136135936
iter:  21500, loss: 0.05611943707801401
iter:  21600, loss: 0.05947849901393056
iter:  21700, loss: 0.061082324367016556
iter:  21800, loss: 0.058185731563717126
iter:  21900, loss: 0.05745304385200143
iter:  22000, loss: 0.05781468946486711
iter:  22100, loss: 0.05523623083718121
iter:  22200, loss: 0.0625031343009323
iter:  22300, loss: 0.057970514316111804
iter:  22400, loss: 0.056746448138728735
iter:  22500, loss: 0.059646447068080304
iter:  22600, loss: 0.05826952626928687
iter:  22700, loss: 0.06291440293192864
iter:  22800, loss: 0.05353044034913182
iter:  22900, loss: 0.05473971040919423
iter:  23000, loss: 0.0608228000625968
iter:  23100, loss: 0.05868493227288127
iter:  23200, loss: 0.060261952225118876
iter:  23300, loss: 0.05965405185706914
iter:  23400, loss: 0.05838587843813002
iter:  23500, loss: 0.059935078965499995
iter:  23600, loss: 0.05876722099259496
iter:  23700, loss: 0.05804253561422229
iter:  23800, loss: 0.057618674263358115
iter:  23900, loss: 0.06035429447889328
iter:  24000, loss: 0.05837280105799437
iter:  24100, loss: 0.05556138496845961
iter:  24200, loss: 0.06101609179750085
iter:  24300, loss: 0.06077233700081706
iter:  24400, loss: 0.05842703541740775
iter:  24500, loss: 0.05470564015209675
iter:  24600, loss: 0.06164334738627076
iter:  24700, loss: 0.061208791946992275
iter:  24800, loss: 0.05579183741472662
iter:  24900, loss: 0.05421525109559298
iter:  25000, loss: 0.06089969849213958
iter:  25100, loss: 0.05896898675709963
iter:  25200, loss: 0.058275629049167034
iter:  25300, loss: 0.06255509808659554
iter:  25400, loss: 0.05790126010775566
iter:  25500, loss: 0.059327758718281984
iter:  25600, loss: 0.057502163369208575
iter:  25700, loss: 0.06044543513096869
iter:  25800, loss: 0.05565543655306101
iter:  25900, loss: 0.05780854184180498
iter:  26000, loss: 0.0561407429818064
iter:  26100, loss: 0.05996781064197421
iter:  26200, loss: 0.05941449411213398
iter:  26300, loss: 0.05793282993137836
iter:  26400, loss: 0.05947942743077874
iter:  26500, loss: 0.05354668610729277
iter:  26600, loss: 0.06097708991728723
iter:  26700, loss: 0.055624489141628146
iter:  26800, loss: 0.05982185742817819
iter:  26900, loss: 0.05769376932643354
iter:  27000, loss: 0.06008958669379354
iter:  27100, loss: 0.05617628190666437
iter:  27200, loss: 0.05586005153134465
iter:  27300, loss: 0.05925918778404594
iter:  27400, loss: 0.05694069342687726
iter:  27500, loss: 0.06373578205704689
iter:  27600, loss: 0.05931739754974842
iter:  27700, loss: 0.05439101604744792
iter:  27800, loss: 0.06186071607284248
iter:  27900, loss: 0.05746053880080581
iter:  28000, loss: 0.05454304589889944
iter:  28100, loss: 0.06014038775116205
iter:  28200, loss: 0.05629007056355476
iter:  28300, loss: 0.056442296486347916
iter:  28400, loss: 0.062244416140019895
iter:  28500, loss: 0.058139360044151545
iter:  28600, loss: 0.05710588201880455
iter:  28700, loss: 0.05910686910152435
iter:  28800, loss: 0.060244659520685674
iter:  28900, loss: 0.05938001621514559
iter:  29000, loss: 0.05750795023515821
iter:  29100, loss: 0.05681804040446878
iter:  29200, loss: 0.0584727353323251
iter:  29300, loss: 0.05835668474435806
iter:  29400, loss: 0.056279961038380864
iter:  29500, loss: 0.058039687369018794
iter:  29600, loss: 0.056454465910792354
iter:  29700, loss: 0.058133271932601926
iter:  29800, loss: 0.05861159154213965
iter:  29900, loss: 0.05578289343044162
iter:  30000, loss: 0.05488736944273114
iter:  30100, loss: 0.05511478714644909
iter:  30200, loss: 0.06175623135641217
iter:  30300, loss: 0.05713110767304897
iter:  30400, loss: 0.05967901568859815
iter:  30500, loss: 0.061916772164404395
iter:  30600, loss: 0.05831842385232448
iter:  30700, loss: 0.056825314536690714
iter:  30800, loss: 0.055738720949739216
iter:  30900, loss: 0.05740627445280552
iter:  31000, loss: 0.058105330429971215
iter:  31100, loss: 0.058154330253601075
iter:  31200, loss: 0.05865230661816895
iter:  31300, loss: 0.058379106875509026
iter:  31400, loss: 0.05937752860598266
iter:  31500, loss: 0.06327276270836592
iter:  31600, loss: 0.0554880721308291
iter:  31700, loss: 0.05343839917331934
iter:  31800, loss: 0.05625346053391695
iter:  31900, loss: 0.06029483987018466
iter:  32000, loss: 0.06028278764337301

The final accuracy is: 89.83
The final error is: 10.17
correct ratio is: 0.898
