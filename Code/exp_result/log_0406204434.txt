Namespace(batch=32, timestamp='0406204434', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='SGD', lr=0.3, momentum=0.9, weight_decay=0.0001, decay_step=5000, lr_decay_rate=0.2, num_iter=32000)

The total number of parameter is: 4.884 M
iter:    100, loss: 3.038972454071045
iter:    200, loss: 2.3093524813652038
iter:    300, loss: 2.29723112821579
iter:    400, loss: 2.2313061213493346
iter:    500, loss: 2.1765729534626006
iter:    600, loss: 2.122329684495926
iter:    700, loss: 2.1470738184452056
iter:    800, loss: 2.113921387195587
iter:    900, loss: 2.1041406214237215
iter:   1000, loss: 2.065530833005905
iter:   1100, loss: 2.051315038204193
iter:   1200, loss: 2.0048617792129515
iter:   1300, loss: 1.929519816637039
iter:   1400, loss: 1.9285194396972656
iter:   1500, loss: 1.9510389161109924
iter:   1600, loss: 1.9140119421482087
iter:   1700, loss: 1.8506264770030976
iter:   1800, loss: 1.8676153647899627
iter:   1900, loss: 1.8080055260658263
iter:   2000, loss: 1.834678715467453
iter:   2100, loss: 1.78767613530159
iter:   2200, loss: 1.7583510375022888
iter:   2300, loss: 1.7713623285293578
iter:   2400, loss: 1.7274219846725465
iter:   2500, loss: 1.7441856181621551
iter:   2600, loss: 1.6641359639167785
iter:   2700, loss: 1.7094730651378631
iter:   2800, loss: 1.6350961005687714
iter:   2900, loss: 1.6530647611618041
iter:   3000, loss: 1.5989740371704102
iter:   3100, loss: 1.5808046996593474
iter:   3200, loss: 1.5680910015106202
iter:   3300, loss: 1.6034249031543732
iter:   3400, loss: 1.569487795829773
iter:   3500, loss: 1.563111094236374
iter:   3600, loss: 1.5162511223554611
iter:   3700, loss: 1.48652174949646
iter:   3800, loss: 1.4685451245307923
iter:   3900, loss: 1.4226851505041123
iter:   4000, loss: 1.4316578793525696
iter:   4100, loss: 1.4459456688165664
iter:   4200, loss: 1.364664876461029
iter:   4300, loss: 1.374432888031006
iter:   4400, loss: 1.3732903999090196
iter:   4500, loss: 1.361144472360611
iter:   4600, loss: 1.3527329725027084
iter:   4700, loss: 1.3350197541713715
iter:   4800, loss: 1.3119488364458085
iter:   4900, loss: 1.2813258385658264
iter:   5000, loss: 1.2725127726793288
iter:   5100, loss: 1.1167042165994645
iter:   5200, loss: 1.0250404477119446
iter:   5300, loss: 1.0966311818361283
iter:   5400, loss: 1.0322384816408157
iter:   5500, loss: 0.9890311092138291
iter:   5600, loss: 0.999640222787857
iter:   5700, loss: 1.0064261484146118
iter:   5800, loss: 0.9877519172430038
iter:   5900, loss: 0.9555135774612427
iter:   6000, loss: 0.984517827630043
iter:   6100, loss: 0.9670127552747726
iter:   6200, loss: 0.9376795315742492
iter:   6300, loss: 0.9444915166497231
iter:   6400, loss: 0.9468542128801346
iter:   6500, loss: 0.923104499578476
iter:   6600, loss: 0.8838740569353104
iter:   6700, loss: 0.8893933802843094
iter:   6800, loss: 0.9203462582826615
iter:   6900, loss: 0.8362894636392594
iter:   7000, loss: 0.8935570919513702
iter:   7100, loss: 0.9103258684277534
iter:   7200, loss: 0.8897825112938881
iter:   7300, loss: 0.8791775476932525
iter:   7400, loss: 0.8902364844083785
iter:   7500, loss: 0.8590634429454803
iter:   7600, loss: 0.8881453490257263
iter:   7700, loss: 0.8645475962758065
iter:   7800, loss: 0.8716051107645035
iter:   7900, loss: 0.8606908351182938
iter:   8000, loss: 0.8467692905664443
iter:   8100, loss: 0.8367579907178879
iter:   8200, loss: 0.8031057813763618
iter:   8300, loss: 0.8581618118286133
iter:   8400, loss: 0.8001755136251449
iter:   8500, loss: 0.8729097574949265
iter:   8600, loss: 0.8106345340609551
iter:   8700, loss: 0.7888084462285042
iter:   8800, loss: 0.7786694324016571
iter:   8900, loss: 0.8295839831233025
iter:   9000, loss: 0.8082392141222954
iter:   9100, loss: 0.7799591049551964
iter:   9200, loss: 0.7651785030961037
iter:   9300, loss: 0.7652243036031723
iter:   9400, loss: 0.7640106666088105
iter:   9500, loss: 0.7358419269323349
iter:   9600, loss: 0.7901733836531639
iter:   9700, loss: 0.7231229084730149
iter:   9800, loss: 0.7563978150486946
iter:   9900, loss: 0.7501033261418343
iter:  10000, loss: 0.7514297384023666
iter:  10100, loss: 0.7127421882748604
iter:  10200, loss: 0.6211176171898842
iter:  10300, loss: 0.628461102694273
iter:  10400, loss: 0.6004896152019501
iter:  10500, loss: 0.6224046248197556
iter:  10600, loss: 0.6229917253553867
iter:  10700, loss: 0.6063093490898609
iter:  10800, loss: 0.6071877688169479
iter:  10900, loss: 0.5922419518232346
iter:  11000, loss: 0.5707870090007782
iter:  11100, loss: 0.5757249429821968
iter:  11200, loss: 0.5305245007574558
iter:  11300, loss: 0.5862294602394104
iter:  11400, loss: 0.5936726078391075
iter:  11500, loss: 0.6018303626775742
iter:  11600, loss: 0.5912729674577712
iter:  11700, loss: 0.5776338948309422
iter:  11800, loss: 0.5760016456246376
iter:  11900, loss: 0.5853682847321033
iter:  12000, loss: 0.5538762873411178
iter:  12100, loss: 0.5515611487627029
iter:  12200, loss: 0.5556230337917805
iter:  12300, loss: 0.5520098787546158
iter:  12400, loss: 0.5501796934008598
iter:  12500, loss: 0.5657496438920497
iter:  12600, loss: 0.5982818946242332
iter:  12700, loss: 0.529187005162239
iter:  12800, loss: 0.5161611568927765
iter:  12900, loss: 0.5067301276326179
iter:  13000, loss: 0.5547932949662209
iter:  13100, loss: 0.5323719218373298
iter:  13200, loss: 0.5451760259270668
iter:  13300, loss: 0.5371163780987263
iter:  13400, loss: 0.5348819926381111
iter:  13500, loss: 0.5303837928175926
iter:  13600, loss: 0.5060168448090553
iter:  13700, loss: 0.49162408590316775
iter:  13800, loss: 0.529449355751276
iter:  13900, loss: 0.5560247933864594
iter:  14000, loss: 0.5331673108041286
iter:  14100, loss: 0.5345085744559764
iter:  14200, loss: 0.5252878448367119
iter:  14300, loss: 0.5134541663527489
iter:  14400, loss: 0.5180207988619805
iter:  14500, loss: 0.4986184310913086
iter:  14600, loss: 0.5190243774652481
iter:  14700, loss: 0.5252602709829808
iter:  14800, loss: 0.479730224609375
iter:  14900, loss: 0.5020209977030754
iter:  15000, loss: 0.5131176263093948
iter:  15100, loss: 0.4840345449745655
iter:  15200, loss: 0.49134059995412827
iter:  15300, loss: 0.4619937291741371
iter:  15400, loss: 0.48156611129641536
iter:  15500, loss: 0.4940180832147598
iter:  15600, loss: 0.4504907490313053
iter:  15700, loss: 0.44962654665112495
iter:  15800, loss: 0.4509568707644939
iter:  15900, loss: 0.4568116055428982
iter:  16000, loss: 0.4385803408920765
iter:  16100, loss: 0.4524357609450817
iter:  16200, loss: 0.4626293580234051
iter:  16300, loss: 0.416294704452157
iter:  16400, loss: 0.45997699350118637
iter:  16500, loss: 0.44497787438333036
iter:  16600, loss: 0.4300948129594326
iter:  16700, loss: 0.4562390670180321
iter:  16800, loss: 0.4537463552504778
iter:  16900, loss: 0.44840416833758356
iter:  17000, loss: 0.453798471391201
iter:  17100, loss: 0.45439773991703986
iter:  17200, loss: 0.45274755239486697
iter:  17300, loss: 0.4371598106622696
iter:  17400, loss: 0.40035867094993594
iter:  17500, loss: 0.4415355731546879
iter:  17600, loss: 0.4388593761622906
iter:  17700, loss: 0.45377195194363595
iter:  17800, loss: 0.4468097612261772
iter:  17900, loss: 0.42771725192666055
iter:  18000, loss: 0.4274372720718384
iter:  18100, loss: 0.4337278324365616
iter:  18200, loss: 0.4332082538306713
iter:  18300, loss: 0.43534834653139115
iter:  18400, loss: 0.4398131030797958
iter:  18500, loss: 0.4427655971050262
iter:  18600, loss: 0.4260354213416576
iter:  18700, loss: 0.4326948991417885
iter:  18800, loss: 0.4427038522064686
iter:  18900, loss: 0.41647738628089426
iter:  19000, loss: 0.40788613840937615
iter:  19100, loss: 0.4414190977811813
iter:  19200, loss: 0.4432583725452423
iter:  19300, loss: 0.4412748970091343
iter:  19400, loss: 0.415713581815362
iter:  19500, loss: 0.4150598979741335
iter:  19600, loss: 0.40628225475549695
iter:  19700, loss: 0.42779344603419306
iter:  19800, loss: 0.3986470119655132
iter:  19900, loss: 0.4523419967293739
iter:  20000, loss: 0.42164749167859555
iter:  20100, loss: 0.4152716897428036
iter:  20200, loss: 0.3936796361207962
iter:  20300, loss: 0.42067610174417497
iter:  20400, loss: 0.4284991820156574
iter:  20500, loss: 0.4002647978067398
iter:  20600, loss: 0.4099983393400908
iter:  20700, loss: 0.42774229422211646
iter:  20800, loss: 0.40546015739440916
iter:  20900, loss: 0.40422576501965524
iter:  21000, loss: 0.3862521423399448
iter:  21100, loss: 0.41890062928199767
iter:  21200, loss: 0.42064291700720785
iter:  21300, loss: 0.38540711760520935
iter:  21400, loss: 0.41880875304341314
iter:  21500, loss: 0.39243841491639614
iter:  21600, loss: 0.39815137669444084
iter:  21700, loss: 0.39514349043369296
iter:  21800, loss: 0.4180069775134325
iter:  21900, loss: 0.4078508386015892
iter:  22000, loss: 0.37492081835865976
iter:  22100, loss: 0.4048963714390993
iter:  22200, loss: 0.39943156398832796
iter:  22300, loss: 0.4142276568710804
iter:  22400, loss: 0.4012978772073984
iter:  22500, loss: 0.39575070738792417
iter:  22600, loss: 0.42150962695479394
iter:  22700, loss: 0.38441882625222207
iter:  22800, loss: 0.3888138197362423
iter:  22900, loss: 0.3941457571834326
iter:  23000, loss: 0.418656003922224
iter:  23100, loss: 0.41529299825429916
iter:  23200, loss: 0.39712346583604813
iter:  23300, loss: 0.40071831494569776
iter:  23400, loss: 0.43054594814777375
iter:  23500, loss: 0.413533037006855
iter:  23600, loss: 0.4052147142589092
iter:  23700, loss: 0.3847977676987648
iter:  23800, loss: 0.41679315954446794
iter:  23900, loss: 0.4226228003948927
iter:  24000, loss: 0.4170572245121002
iter:  24100, loss: 0.3915857866406441
iter:  24200, loss: 0.38610155895352366
iter:  24300, loss: 0.42075156413018705
iter:  24400, loss: 0.38855775773525236
iter:  24500, loss: 0.40529395774006843
iter:  24600, loss: 0.39698310986161234
iter:  24700, loss: 0.38341552421450614
iter:  24800, loss: 0.4093483245372772
iter:  24900, loss: 0.38915815740823745
iter:  25000, loss: 0.38330525428056716
iter:  25100, loss: 0.3969665542244911
iter:  25200, loss: 0.40037283778190613
iter:  25300, loss: 0.39319218069314954
iter:  25400, loss: 0.4028200156986713
iter:  25500, loss: 0.37499748297035695
iter:  25600, loss: 0.3732536263763905
iter:  25700, loss: 0.4094417417049408
iter:  25800, loss: 0.3585446830093861
iter:  25900, loss: 0.406876323223114
iter:  26000, loss: 0.40318332344293595
iter:  26100, loss: 0.376791575178504
iter:  26200, loss: 0.3965014785528183
iter:  26300, loss: 0.3891457922011614
iter:  26400, loss: 0.407164124250412
iter:  26500, loss: 0.3928940511494875
iter:  26600, loss: 0.3948577067255974
iter:  26700, loss: 0.3833027356863022
iter:  26800, loss: 0.4092359194159508
iter:  26900, loss: 0.383217062279582
iter:  27000, loss: 0.40373439103364944
iter:  27100, loss: 0.3942850585281849
iter:  27200, loss: 0.3914802695810795
iter:  27300, loss: 0.3592861969769001
iter:  27400, loss: 0.39374135866761206
iter:  27500, loss: 0.38750546783208845
iter:  27600, loss: 0.4115327778458595
iter:  27700, loss: 0.3739945091307163
iter:  27800, loss: 0.39853191390633586
iter:  27900, loss: 0.38739277094602587
iter:  28000, loss: 0.4264272966235876
iter:  28100, loss: 0.40363653637468816
iter:  28200, loss: 0.39417104676365855
iter:  28300, loss: 0.4076295705139637
iter:  28400, loss: 0.4107974998652935
iter:  28500, loss: 0.38268970444798467
iter:  28600, loss: 0.4046137470006943
iter:  28700, loss: 0.3700544562935829
iter:  28800, loss: 0.39613072246313097
iter:  28900, loss: 0.38740932539105416
iter:  29000, loss: 0.41378301322460176
iter:  29100, loss: 0.38351162485778334
iter:  29200, loss: 0.3799070531874895
iter:  29300, loss: 0.3826549044251442
iter:  29400, loss: 0.4126762370765209
iter:  29500, loss: 0.39484175369143487
iter:  29600, loss: 0.3907386939227581
iter:  29700, loss: 0.4115288431942463
iter:  29800, loss: 0.39642713449895384
iter:  29900, loss: 0.36882104597985743
iter:  30000, loss: 0.4134099392592907
iter:  30100, loss: 0.3776560862362385
iter:  30200, loss: 0.3989611254632473
iter:  30300, loss: 0.37149173751473424
iter:  30400, loss: 0.3865053278207779
iter:  30500, loss: 0.38191864773631096
iter:  30600, loss: 0.36828147068619727
iter:  30700, loss: 0.4192603951692581
iter:  30800, loss: 0.39111622393131257
iter:  30900, loss: 0.3957364822179079
iter:  31000, loss: 0.38831812895834444
iter:  31100, loss: 0.38039087936282157
iter:  31200, loss: 0.38403667710721495
iter:  31300, loss: 0.39193505272269247
iter:  31400, loss: 0.4091694501042366
iter:  31500, loss: 0.38265723928809164
iter:  31600, loss: 0.3971433502435684
iter:  31700, loss: 0.3842101593315601
iter:  31800, loss: 0.40831544540822506
iter:  31900, loss: 0.372460548132658
iter:  32000, loss: 0.39400566548109056

The final accuracy is: 84.96
The final error is: 15.04
correct ratio is: 0.85
