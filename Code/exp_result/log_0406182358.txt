Namespace(batch=64, timestamp='0406182358', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='Adagrad', lr=0.1, momentum=0.9, weight_decay=0.0001, decay_step=5000, lr_decay_rate=0.2, num_iter=32000)

The total number of parameter is: 4.884 M
iter:    100, loss: 2.568372699022293
iter:    200, loss: 2.0292228436470032
iter:    300, loss: 1.9742677223682403
iter:    400, loss: 1.9082376706600188
iter:    500, loss: 1.8408597922325134
iter:    600, loss: 1.7794433319568634
iter:    700, loss: 1.709159528017044
iter:    800, loss: 1.6836741328239442
iter:    900, loss: 1.624860588312149
iter:   1000, loss: 1.6195158851146698
iter:   1100, loss: 1.5529121661186218
iter:   1200, loss: 1.5322129487991334
iter:   1300, loss: 1.4814485359191893
iter:   1400, loss: 1.4546288287639617
iter:   1500, loss: 1.44281418800354
iter:   1600, loss: 1.3865555381774903
iter:   1700, loss: 1.3659458291530608
iter:   1800, loss: 1.3337874495983124
iter:   1900, loss: 1.3200044846534729
iter:   2000, loss: 1.2880857837200166
iter:   2100, loss: 1.2535534888505935
iter:   2200, loss: 1.2606808513402938
iter:   2300, loss: 1.2179569375514985
iter:   2400, loss: 1.21006462931633
iter:   2500, loss: 1.182292895913124
iter:   2600, loss: 1.1567331087589263
iter:   2700, loss: 1.1672951543331147
iter:   2800, loss: 1.137637335062027
iter:   2900, loss: 1.136672939658165
iter:   3000, loss: 1.1011246913671493
iter:   3100, loss: 1.0680802023410798
iter:   3200, loss: 1.0526312536001206
iter:   3300, loss: 1.0155465239286423
iter:   3400, loss: 1.024474602341652
iter:   3500, loss: 1.0157887792587281
iter:   3600, loss: 0.9915732711553573
iter:   3700, loss: 0.9912468194961548
iter:   3800, loss: 0.9595422756671905
iter:   3900, loss: 0.9442110288143158
iter:   4000, loss: 0.9034397673606872
iter:   4100, loss: 0.9180550110340119
iter:   4200, loss: 0.8987570071220398
iter:   4300, loss: 0.8915852308273315
iter:   4400, loss: 0.8786657762527466
iter:   4500, loss: 0.8558582055568695
iter:   4600, loss: 0.8655250442028045
iter:   4700, loss: 0.8532182428240777
iter:   4800, loss: 0.8362297129631042
iter:   4900, loss: 0.7796434471011162
iter:   5000, loss: 0.7924082595109939
iter:   5100, loss: 0.7216744542121887
iter:   5200, loss: 0.7083020380139351
iter:   5300, loss: 0.7030063793063164
iter:   5400, loss: 0.6947711837291718
iter:   5500, loss: 0.6852194032073021
iter:   5600, loss: 0.6558598110079765
iter:   5700, loss: 0.6523711788654327
iter:   5800, loss: 0.6615298733115196
iter:   5900, loss: 0.6495446062088013
iter:   6000, loss: 0.6528317043185234
iter:   6100, loss: 0.6418454271554946
iter:   6200, loss: 0.6376271098852158
iter:   6300, loss: 0.6139822432398796
iter:   6400, loss: 0.6446573597192764
iter:   6500, loss: 0.6086785313487053
iter:   6600, loss: 0.640660189986229
iter:   6700, loss: 0.5905450683832169
iter:   6800, loss: 0.5874268963932991
iter:   6900, loss: 0.5981502750515938
iter:   7000, loss: 0.6002190724015236
iter:   7100, loss: 0.5739597260951996
iter:   7200, loss: 0.5756543454527855
iter:   7300, loss: 0.5754319462180137
iter:   7400, loss: 0.5780602046847343
iter:   7500, loss: 0.585249905884266
iter:   7600, loss: 0.5760116085410119
iter:   7700, loss: 0.5663743129372597
iter:   7800, loss: 0.5523882347345352
iter:   7900, loss: 0.5729573541879653
iter:   8000, loss: 0.5572848692536354
iter:   8100, loss: 0.5204919123649597
iter:   8200, loss: 0.5611854359507561
iter:   8300, loss: 0.5375803798437119
iter:   8400, loss: 0.5263829320669174
iter:   8500, loss: 0.5449199375510215
iter:   8600, loss: 0.5414332026243209
iter:   8700, loss: 0.5225103199481964
iter:   8800, loss: 0.531544688642025
iter:   8900, loss: 0.510299502313137
iter:   9000, loss: 0.5256054744124412
iter:   9100, loss: 0.5177701592445374
iter:   9200, loss: 0.4963432949781418
iter:   9300, loss: 0.5073112517595291
iter:   9400, loss: 0.5200215747952461
iter:   9500, loss: 0.4898754225671291
iter:   9600, loss: 0.49147561341524126
iter:   9700, loss: 0.47380256503820417
iter:   9800, loss: 0.490882380604744
iter:   9900, loss: 0.48749797269701955
iter:  10000, loss: 0.4933694505691528
iter:  10100, loss: 0.4854422670602798
iter:  10200, loss: 0.4565426251292229
iter:  10300, loss: 0.44493463799357413
iter:  10400, loss: 0.4348538315296173
iter:  10500, loss: 0.4426735930144787
iter:  10600, loss: 0.430133788138628
iter:  10700, loss: 0.4515506911277771
iter:  10800, loss: 0.4406559729576111
iter:  10900, loss: 0.4433000081777573
iter:  11000, loss: 0.43427048847079275
iter:  11100, loss: 0.429007705450058
iter:  11200, loss: 0.42865753203630447
iter:  11300, loss: 0.4134738466143608
iter:  11400, loss: 0.4380976319313049
iter:  11500, loss: 0.42902870893478395
iter:  11600, loss: 0.41778604313731194
iter:  11700, loss: 0.43169863522052765
iter:  11800, loss: 0.4209686115384102
iter:  11900, loss: 0.4242351619899273
iter:  12000, loss: 0.4175418120622635
iter:  12100, loss: 0.41332818150520323
iter:  12200, loss: 0.4107867123186588
iter:  12300, loss: 0.4263661631941795
iter:  12400, loss: 0.427463698387146
iter:  12500, loss: 0.43512304544448854
iter:  12600, loss: 0.4266114382445812
iter:  12700, loss: 0.40398709923028947
iter:  12800, loss: 0.42835371345281603
iter:  12900, loss: 0.39307863637804985
iter:  13000, loss: 0.4136791743338108
iter:  13100, loss: 0.40708708375692365
iter:  13200, loss: 0.3992190943658352
iter:  13300, loss: 0.4035947850346565
iter:  13400, loss: 0.3918082219362259
iter:  13500, loss: 0.40469848707318307
iter:  13600, loss: 0.3991415052115917
iter:  13700, loss: 0.39892659544944764
iter:  13800, loss: 0.40389208391308784
iter:  13900, loss: 0.4062841206789017
iter:  14000, loss: 0.4051846852898598
iter:  14100, loss: 0.3989226776361465
iter:  14200, loss: 0.37594178050756455
iter:  14300, loss: 0.40731609478592873
iter:  14400, loss: 0.3864962430298328
iter:  14500, loss: 0.37713244423270226
iter:  14600, loss: 0.3803885094821453
iter:  14700, loss: 0.39179674565792083
iter:  14800, loss: 0.39212381199002266
iter:  14900, loss: 0.38299503073096275
iter:  15000, loss: 0.3948038989305496
iter:  15100, loss: 0.3784286978840828
iter:  15200, loss: 0.3870530951023102
iter:  15300, loss: 0.3826467204093933
iter:  15400, loss: 0.38767198860645297
iter:  15500, loss: 0.3919673551619053
iter:  15600, loss: 0.38592954888939857
iter:  15700, loss: 0.3691023460030556
iter:  15800, loss: 0.3735458414256573
iter:  15900, loss: 0.3862905777990818
iter:  16000, loss: 0.39121697247028353
iter:  16100, loss: 0.3662137870490551
iter:  16200, loss: 0.3813995072245598
iter:  16300, loss: 0.3779854157567024
iter:  16400, loss: 0.3868075360357761
iter:  16500, loss: 0.3745968364179134
iter:  16600, loss: 0.38330945461988447
iter:  16700, loss: 0.3811304272711277
iter:  16800, loss: 0.3807227736711502
iter:  16900, loss: 0.37215546518564224
iter:  17000, loss: 0.366834003329277
iter:  17100, loss: 0.39012382209300994
iter:  17200, loss: 0.37837965741753576
iter:  17300, loss: 0.3763916151225567
iter:  17400, loss: 0.3819970390200615
iter:  17500, loss: 0.37487667575478556
iter:  17600, loss: 0.385957817286253
iter:  17700, loss: 0.36018134772777555
iter:  17800, loss: 0.37932410061359406
iter:  17900, loss: 0.35545612752437594
iter:  18000, loss: 0.37344923928380014
iter:  18100, loss: 0.36082359656691554
iter:  18200, loss: 0.38434149727225303
iter:  18300, loss: 0.38348167791962623
iter:  18400, loss: 0.37798528745770454
iter:  18500, loss: 0.37110128849744795
iter:  18600, loss: 0.3732347600162029
iter:  18700, loss: 0.3780223760008812
iter:  18800, loss: 0.363217758834362
iter:  18900, loss: 0.38914156675338746
iter:  19000, loss: 0.37805404216051103
iter:  19100, loss: 0.35620091125369074
iter:  19200, loss: 0.3674285811185837
iter:  19300, loss: 0.3680958054959774
iter:  19400, loss: 0.3646432910859585
iter:  19500, loss: 0.37958485543727877
iter:  19600, loss: 0.36641851022839544
iter:  19700, loss: 0.38183070920407775
iter:  19800, loss: 0.38173552870750427
iter:  19900, loss: 0.3628175261616707
iter:  20000, loss: 0.3753267113864422
iter:  20100, loss: 0.3743118195235729
iter:  20200, loss: 0.3572947034239769
iter:  20300, loss: 0.3699565036594868
iter:  20400, loss: 0.3644209659099579
iter:  20500, loss: 0.36066973879933356
iter:  20600, loss: 0.3571733568608761
iter:  20700, loss: 0.37233888283371924
iter:  20800, loss: 0.38062865659594536
iter:  20900, loss: 0.37405065953731537
iter:  21000, loss: 0.36355302527546884
iter:  21100, loss: 0.35989242888987066
iter:  21200, loss: 0.3603246781229973
iter:  21300, loss: 0.3679669760167599
iter:  21400, loss: 0.35755805045366285
iter:  21500, loss: 0.37932650551199915
iter:  21600, loss: 0.37630019947886467
iter:  21700, loss: 0.35288635700941084
iter:  21800, loss: 0.38044214233756063
iter:  21900, loss: 0.3671154913306236
iter:  22000, loss: 0.37461315959692
iter:  22100, loss: 0.37411608144640923
iter:  22200, loss: 0.36986723497509955
iter:  22300, loss: 0.36177708476781845
iter:  22400, loss: 0.3661675940454006
iter:  22500, loss: 0.36724085465073586
iter:  22600, loss: 0.3716750691831112
iter:  22700, loss: 0.36553984075784685
iter:  22800, loss: 0.3699346198141575
iter:  22900, loss: 0.36663322180509567
iter:  23000, loss: 0.3825410196185112
iter:  23100, loss: 0.3724306781589985
iter:  23200, loss: 0.35456205561757087
iter:  23300, loss: 0.3596217893064022
iter:  23400, loss: 0.358970867395401
iter:  23500, loss: 0.3586846099793911
iter:  23600, loss: 0.36702238708734514
iter:  23700, loss: 0.35304328545928
iter:  23800, loss: 0.3442924642562866
iter:  23900, loss: 0.3754930631816387
iter:  24000, loss: 0.38006018310785294
iter:  24100, loss: 0.3771842359006405
iter:  24200, loss: 0.3746058359742165
iter:  24300, loss: 0.3713999819755554
iter:  24400, loss: 0.36188432946801186
iter:  24500, loss: 0.3600033125281334
iter:  24600, loss: 0.38002325311303137
iter:  24700, loss: 0.3613261550664902
iter:  24800, loss: 0.36397622972726823
iter:  24900, loss: 0.3641634939610958
iter:  25000, loss: 0.37337937608361244
iter:  25100, loss: 0.3644462643563747
iter:  25200, loss: 0.3637899711728096
iter:  25300, loss: 0.35716378018260003
iter:  25400, loss: 0.37152267202734945
iter:  25500, loss: 0.35618999108672145
iter:  25600, loss: 0.37366007283329966
iter:  25700, loss: 0.38145834907889364
iter:  25800, loss: 0.36759808391332627
iter:  25900, loss: 0.373100296407938
iter:  26000, loss: 0.37920635506510736
iter:  26100, loss: 0.36709927543997767
iter:  26200, loss: 0.3743824131786823
iter:  26300, loss: 0.3713951514661312
iter:  26400, loss: 0.3674993218481541
iter:  26500, loss: 0.3644797846674919
iter:  26600, loss: 0.3824523903429508
iter:  26700, loss: 0.3732880030572414
iter:  26800, loss: 0.37349133744835855
iter:  26900, loss: 0.3662388511002064
iter:  27000, loss: 0.36357383444905284
iter:  27100, loss: 0.3697421082854271
iter:  27200, loss: 0.39344734966754913
iter:  27300, loss: 0.34505177795886993
iter:  27400, loss: 0.3529791238903999
iter:  27500, loss: 0.35876080229878426
iter:  27600, loss: 0.35021908193826673
iter:  27700, loss: 0.36966747641563413
iter:  27800, loss: 0.3957999587059021
iter:  27900, loss: 0.3885308112204075
iter:  28000, loss: 0.3605581945180893
iter:  28100, loss: 0.3591690321266651
iter:  28200, loss: 0.3826308152079582
iter:  28300, loss: 0.3574506349861622
iter:  28400, loss: 0.37174284636974336
iter:  28500, loss: 0.35267076790332796
iter:  28600, loss: 0.3737231847643852
iter:  28700, loss: 0.37100039556622505
iter:  28800, loss: 0.36163340523839
iter:  28900, loss: 0.36640231356024744
iter:  29000, loss: 0.37193666860461233
iter:  29100, loss: 0.3511091002821922
iter:  29200, loss: 0.37771099999547003
iter:  29300, loss: 0.3629187865555286
iter:  29400, loss: 0.3605068328976631
iter:  29500, loss: 0.37022258564829824
iter:  29600, loss: 0.3736012926697731
iter:  29700, loss: 0.3621498003602028
iter:  29800, loss: 0.37016929402947424
iter:  29900, loss: 0.3727031198143959
iter:  30000, loss: 0.3621525892615318
iter:  30100, loss: 0.3633997321128845
iter:  30200, loss: 0.3709184391796589
iter:  30300, loss: 0.349962971508503
iter:  30400, loss: 0.3720204788446426
iter:  30500, loss: 0.38355968877673147
iter:  30600, loss: 0.3727849319577217
iter:  30700, loss: 0.3564750894904137
iter:  30800, loss: 0.3638395729660988
iter:  30900, loss: 0.3695767749845982
iter:  31000, loss: 0.3689378234744072
iter:  31100, loss: 0.3615305282175541
iter:  31200, loss: 0.3690313792228699
iter:  31300, loss: 0.37671608850359917
iter:  31400, loss: 0.3479057404398918
iter:  31500, loss: 0.3802819018810987
iter:  31600, loss: 0.37014740526676176
iter:  31700, loss: 0.35918420761823655
iter:  31800, loss: 0.35966082364320756
iter:  31900, loss: 0.36313848063349724
iter:  32000, loss: 0.37454400897026063

The final accuracy is: 84.9
The final error is: 15.1
correct ratio is: 0.849
