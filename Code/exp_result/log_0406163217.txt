Namespace(batch=64, timestamp='0406163217', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='SGD', lr=0.3, momentum=0.9, weight_decay=0.0001, decay_step=5000, lr_decay_rate=0.2, num_iter=32000)

The total number of parameter is: 4.884 M
iter:    100, loss: 3.139055335521698
iter:    200, loss: 2.308093867301941
iter:    300, loss: 2.2901553535461425
iter:    400, loss: 2.1762900447845457
iter:    500, loss: 2.063418139219284
iter:    600, loss: 1.9842959284782409
iter:    700, loss: 1.9651978945732116
iter:    800, loss: 1.8983856964111328
iter:    900, loss: 1.8542189586162567
iter:   1000, loss: 1.8135976135730743
iter:   1100, loss: 1.7880012226104736
iter:   1200, loss: 1.7727033376693726
iter:   1300, loss: 1.7017586314678192
iter:   1400, loss: 1.6746794593334198
iter:   1500, loss: 1.6370861113071442
iter:   1600, loss: 1.6343360948562622
iter:   1700, loss: 1.5851484835147858
iter:   1800, loss: 1.5442455446720122
iter:   1900, loss: 1.478682689666748
iter:   2000, loss: 1.465873829126358
iter:   2100, loss: 1.4562665927410126
iter:   2200, loss: 1.4092092955112456
iter:   2300, loss: 1.3396321618556977
iter:   2400, loss: 1.357480137348175
iter:   2500, loss: 1.2727278035879135
iter:   2600, loss: 1.2676601833105088
iter:   2700, loss: 1.229919472336769
iter:   2800, loss: 1.2016980016231538
iter:   2900, loss: 1.1500087440013886
iter:   3000, loss: 1.1342098170518875
iter:   3100, loss: 1.1171445816755294
iter:   3200, loss: 1.0322080874443054
iter:   3300, loss: 1.031182240843773
iter:   3400, loss: 0.9828155201673507
iter:   3500, loss: 0.9698650157451629
iter:   3600, loss: 0.9803607648611069
iter:   3700, loss: 0.9620990580320359
iter:   3800, loss: 0.9655810546875
iter:   3900, loss: 0.935319214463234
iter:   4000, loss: 0.9068460470438003
iter:   4100, loss: 0.8811268764734268
iter:   4200, loss: 0.873989759683609
iter:   4300, loss: 0.852049708366394
iter:   4400, loss: 0.84793077647686
iter:   4500, loss: 0.8313870626688004
iter:   4600, loss: 0.8321028035879136
iter:   4700, loss: 0.8074588868021965
iter:   4800, loss: 0.7941685372591019
iter:   4900, loss: 0.790568051636219
iter:   5000, loss: 0.7926291179656982
iter:   5100, loss: 0.6887789279222488
iter:   5200, loss: 0.6119164633750915
iter:   5300, loss: 0.6185133683681489
iter:   5400, loss: 0.5738530361652374
iter:   5500, loss: 0.5541646657884121
iter:   5600, loss: 0.5547360077500343
iter:   5700, loss: 0.5344174963235855
iter:   5800, loss: 0.5553823891282081
iter:   5900, loss: 0.5530702358484268
iter:   6000, loss: 0.5390077072381974
iter:   6100, loss: 0.5485103511810303
iter:   6200, loss: 0.5235152772068977
iter:   6300, loss: 0.5103105452656745
iter:   6400, loss: 0.4920055711269379
iter:   6500, loss: 0.5109839472174644
iter:   6600, loss: 0.5093882058560848
iter:   6700, loss: 0.5029877476394177
iter:   6800, loss: 0.5088445979356766
iter:   6900, loss: 0.5102868282794952
iter:   7000, loss: 0.5219602823257447
iter:   7100, loss: 0.4925332799553871
iter:   7200, loss: 0.4602376718819141
iter:   7300, loss: 0.4993236969411373
iter:   7400, loss: 0.4728847885131836
iter:   7500, loss: 0.4721800884604454
iter:   7600, loss: 0.4797479246556759
iter:   7700, loss: 0.46644784152507784
iter:   7800, loss: 0.46763990879058837
iter:   7900, loss: 0.4486226014792919
iter:   8000, loss: 0.44758599773049357
iter:   8100, loss: 0.46459138244390485
iter:   8200, loss: 0.4771105220913887
iter:   8300, loss: 0.46984124958515167
iter:   8400, loss: 0.46026779264211654
iter:   8500, loss: 0.44311959207057955
iter:   8600, loss: 0.4552491682767868
iter:   8700, loss: 0.4304867589473724
iter:   8800, loss: 0.4297768504917622
iter:   8900, loss: 0.45035803347826003
iter:   9000, loss: 0.4407000134885311
iter:   9100, loss: 0.44729146391153335
iter:   9200, loss: 0.45250417679548266
iter:   9300, loss: 0.45414727717638015
iter:   9400, loss: 0.4138225170969963
iter:   9500, loss: 0.4183852206170559
iter:   9600, loss: 0.42152021542191503
iter:   9700, loss: 0.40876746237277983
iter:   9800, loss: 0.42847085893154147
iter:   9900, loss: 0.4259725533425808
iter:  10000, loss: 0.41876669496297836
iter:  10100, loss: 0.3955750584602356
iter:  10200, loss: 0.36608856499195097
iter:  10300, loss: 0.3415215817093849
iter:  10400, loss: 0.320020934343338
iter:  10500, loss: 0.31842080384492877
iter:  10600, loss: 0.3183391670882702
iter:  10700, loss: 0.32198216803371904
iter:  10800, loss: 0.32627597868442537
iter:  10900, loss: 0.3159224645793438
iter:  11000, loss: 0.30018489822745326
iter:  11100, loss: 0.30121767908334734
iter:  11200, loss: 0.2995396675169468
iter:  11300, loss: 0.2905360119044781
iter:  11400, loss: 0.28771106980741024
iter:  11500, loss: 0.30395543165504935
iter:  11600, loss: 0.3099672260135412
iter:  11700, loss: 0.28852502040565015
iter:  11800, loss: 0.2844423207640648
iter:  11900, loss: 0.27184144355356693
iter:  12000, loss: 0.2753449212759733
iter:  12100, loss: 0.2858480630069971
iter:  12200, loss: 0.30256904408335683
iter:  12300, loss: 0.309407103061676
iter:  12400, loss: 0.2825360542535782
iter:  12500, loss: 0.2861577459424734
iter:  12600, loss: 0.2993191073834896
iter:  12700, loss: 0.2597172649204731
iter:  12800, loss: 0.2604433285444975
iter:  12900, loss: 0.2864465892314911
iter:  13000, loss: 0.27131249591708184
iter:  13100, loss: 0.2840765479207039
iter:  13200, loss: 0.2841360443085432
iter:  13300, loss: 0.2630714486539364
iter:  13400, loss: 0.25753817800432444
iter:  13500, loss: 0.2540728575736284
iter:  13600, loss: 0.25643313087522984
iter:  13700, loss: 0.25512462951242926
iter:  13800, loss: 0.26643198873847723
iter:  13900, loss: 0.2578235885500908
iter:  14000, loss: 0.26300371810793877
iter:  14100, loss: 0.2737460850179195
iter:  14200, loss: 0.25495996840298174
iter:  14300, loss: 0.2593167906999588
iter:  14400, loss: 0.25781559623777867
iter:  14500, loss: 0.26274431608617305
iter:  14600, loss: 0.2599473036080599
iter:  14700, loss: 0.2406083844602108
iter:  14800, loss: 0.2501638682186604
iter:  14900, loss: 0.25207152642309666
iter:  15000, loss: 0.2372868587821722
iter:  15100, loss: 0.24288908764719963
iter:  15200, loss: 0.20603545442223548
iter:  15300, loss: 0.21940604999661445
iter:  15400, loss: 0.23095093466341496
iter:  15500, loss: 0.22320953875780106
iter:  15600, loss: 0.21956638485193253
iter:  15700, loss: 0.21569532871246339
iter:  15800, loss: 0.20742578506469728
iter:  15900, loss: 0.21448612090200186
iter:  16000, loss: 0.19821696750819684
iter:  16100, loss: 0.2136262008547783
iter:  16200, loss: 0.19447678957134484
iter:  16300, loss: 0.20852013759315013
iter:  16400, loss: 0.20300843589007855
iter:  16500, loss: 0.19301488161087035
iter:  16600, loss: 0.2040812273323536
iter:  16700, loss: 0.19145347073674202
iter:  16800, loss: 0.20084040507674217
iter:  16900, loss: 0.20473954625427723
iter:  17000, loss: 0.19359514489769936
iter:  17100, loss: 0.2130423051863909
iter:  17200, loss: 0.21250274904072286
iter:  17300, loss: 0.19318389527499677
iter:  17400, loss: 0.20465220555663108
iter:  17500, loss: 0.19693048231303692
iter:  17600, loss: 0.20462882839143276
iter:  17700, loss: 0.1843984477967024
iter:  17800, loss: 0.207879283092916
iter:  17900, loss: 0.19169335551559924
iter:  18000, loss: 0.19608317621052265
iter:  18100, loss: 0.20113528676331044
iter:  18200, loss: 0.1873216637969017
iter:  18300, loss: 0.1956635931879282
iter:  18400, loss: 0.1996502234786749
iter:  18500, loss: 0.19235762123018504
iter:  18600, loss: 0.1948669920116663
iter:  18700, loss: 0.1928137492761016
iter:  18800, loss: 0.20526977974921465
iter:  18900, loss: 0.1922204675152898
iter:  19000, loss: 0.1809122572094202
iter:  19100, loss: 0.18715600147843361
iter:  19200, loss: 0.1812387438490987
iter:  19300, loss: 0.18177128165960313
iter:  19400, loss: 0.18567621558904648
iter:  19500, loss: 0.17967529263347387
iter:  19600, loss: 0.1823387010395527
iter:  19700, loss: 0.18093560492619873
iter:  19800, loss: 0.18044419053941965
iter:  19900, loss: 0.18506804890930653
iter:  20000, loss: 0.1859142281860113
iter:  20100, loss: 0.18189293175935745
iter:  20200, loss: 0.1908652215823531
iter:  20300, loss: 0.19037821043282746
iter:  20400, loss: 0.17536018166691064
iter:  20500, loss: 0.1759191582724452
iter:  20600, loss: 0.17783651050180196
iter:  20700, loss: 0.16366753976792098
iter:  20800, loss: 0.15288859117776155
iter:  20900, loss: 0.1789407194033265
iter:  21000, loss: 0.17915424484759568
iter:  21100, loss: 0.1794918317347765
iter:  21200, loss: 0.16727365966886282
iter:  21300, loss: 0.17352691523730754
iter:  21400, loss: 0.17853270849213004
iter:  21500, loss: 0.17523665856570006
iter:  21600, loss: 0.17646132331341505
iter:  21700, loss: 0.17444947063922883
iter:  21800, loss: 0.18271199136972427
iter:  21900, loss: 0.1595654460042715
iter:  22000, loss: 0.16776933033019303
iter:  22100, loss: 0.17484475027769805
iter:  22200, loss: 0.16098848771303892
iter:  22300, loss: 0.16744626414030792
iter:  22400, loss: 0.17378243625164033
iter:  22500, loss: 0.17830028895288705
iter:  22600, loss: 0.17034032694995405
iter:  22700, loss: 0.16647312998771668
iter:  22800, loss: 0.16754202008247376
iter:  22900, loss: 0.16128499437123536
iter:  23000, loss: 0.1638408277183771
iter:  23100, loss: 0.17069033466279507
iter:  23200, loss: 0.16709487956017255
iter:  23300, loss: 0.17353817105293273
iter:  23400, loss: 0.1634386272355914
iter:  23500, loss: 0.17513995191082357
iter:  23600, loss: 0.14581620045006274
iter:  23700, loss: 0.1751820756494999
iter:  23800, loss: 0.16585811469703912
iter:  23900, loss: 0.17299180809408427
iter:  24000, loss: 0.16933645103126765
iter:  24100, loss: 0.18103816639631987
iter:  24200, loss: 0.16386661008000375
iter:  24300, loss: 0.16592787720263005
iter:  24400, loss: 0.15840750977396964
iter:  24500, loss: 0.16196475975215435
iter:  24600, loss: 0.1765971405059099
iter:  24700, loss: 0.16893701788038015
iter:  24800, loss: 0.16140264615416527
iter:  24900, loss: 0.1714768448844552
iter:  25000, loss: 0.16867659501731397
iter:  25100, loss: 0.16824147015810012
iter:  25200, loss: 0.1702247120067477
iter:  25300, loss: 0.16911421284079553
iter:  25400, loss: 0.171443211697042
iter:  25500, loss: 0.15843993484973906
iter:  25600, loss: 0.16744266085326673
iter:  25700, loss: 0.16558032765984534
iter:  25800, loss: 0.1566479853913188
iter:  25900, loss: 0.1703563839197159
iter:  26000, loss: 0.16450469739735127
iter:  26100, loss: 0.15913793057203293
iter:  26200, loss: 0.17230490021407605
iter:  26300, loss: 0.1667593912780285
iter:  26400, loss: 0.16134258318692446
iter:  26500, loss: 0.16301649898290635
iter:  26600, loss: 0.1623742863535881
iter:  26700, loss: 0.1748909279704094
iter:  26800, loss: 0.15946678940206765
iter:  26900, loss: 0.1685806175507605
iter:  27000, loss: 0.17250969354063272
iter:  27100, loss: 0.15277103129774333
iter:  27200, loss: 0.1679253276437521
iter:  27300, loss: 0.15840050961822272
iter:  27400, loss: 0.17370662858709693
iter:  27500, loss: 0.15355925336480142
iter:  27600, loss: 0.170340136885643
iter:  27700, loss: 0.16412122003734111
iter:  27800, loss: 0.15297103255987168
iter:  27900, loss: 0.15897748365998268
iter:  28000, loss: 0.175884083583951
iter:  28100, loss: 0.17182412274181844
iter:  28200, loss: 0.1665077155828476
iter:  28300, loss: 0.16797074746340512
iter:  28400, loss: 0.16424920536577703
iter:  28500, loss: 0.16280629511922598
iter:  28600, loss: 0.16411503817886114
iter:  28700, loss: 0.1590114013105631
iter:  28800, loss: 0.16213726062327624
iter:  28900, loss: 0.16248652882874012
iter:  29000, loss: 0.16107510272413492
iter:  29100, loss: 0.17421951450407505
iter:  29200, loss: 0.15832765508443117
iter:  29300, loss: 0.164750197827816
iter:  29400, loss: 0.1619788802228868
iter:  29500, loss: 0.16564025092869997
iter:  29600, loss: 0.15472493194043635
iter:  29700, loss: 0.1526624645292759
iter:  29800, loss: 0.1718955434858799
iter:  29900, loss: 0.16547194648534058
iter:  30000, loss: 0.15476868335157634
iter:  30100, loss: 0.16773215465247632
iter:  30200, loss: 0.15716874577105044
iter:  30300, loss: 0.1567971421033144
iter:  30400, loss: 0.16152643725275995
iter:  30500, loss: 0.17407420836389065
iter:  30600, loss: 0.16876811902970076
iter:  30700, loss: 0.1613471109420061
iter:  30800, loss: 0.1596602980606258
iter:  30900, loss: 0.16869097225368024
iter:  31000, loss: 0.16579618375748395
iter:  31100, loss: 0.16980081297457217
iter:  31200, loss: 0.1567759695276618
iter:  31300, loss: 0.1559836586751044
iter:  31400, loss: 0.16832276552915573
iter:  31500, loss: 0.1622401222586632
iter:  31600, loss: 0.15595720641314983
iter:  31700, loss: 0.16233264591544866
iter:  31800, loss: 0.16119475152343513
iter:  31900, loss: 0.16151233114302158
iter:  32000, loss: 0.16243221640586852

The final accuracy is: 89.31
The final error is: 10.69
correct ratio is: 0.893
