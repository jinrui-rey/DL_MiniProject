Namespace(batch=64, timestamp='0406175340', dataset_dir='./dataset', checkpoint_dir='./checkpoint', print_freq=100, optimizer='ASGD', lr=0.1, momentum=0.9, weight_decay=0.0001, decay_step=5000, lr_decay_rate=0.2, num_iter=32000)

The total number of parameter is: 4.884 M
iter:    100, loss: 2.145043283700943
iter:    200, loss: 1.8298890781402588
iter:    300, loss: 1.738458741903305
iter:    400, loss: 1.6711092126369476
iter:    500, loss: 1.583251256942749
iter:    600, loss: 1.5123897993564606
iter:    700, loss: 1.4530183386802673
iter:    800, loss: 1.391073968410492
iter:    900, loss: 1.3264036965370178
iter:   1000, loss: 1.2670340269804001
iter:   1100, loss: 1.2286840730905533
iter:   1200, loss: 1.1509982806444168
iter:   1300, loss: 1.1212478667497634
iter:   1400, loss: 1.0896555346250534
iter:   1500, loss: 1.035070899128914
iter:   1600, loss: 1.0433249968290328
iter:   1700, loss: 0.9856950896978378
iter:   1800, loss: 0.922657597064972
iter:   1900, loss: 0.9006920075416565
iter:   2000, loss: 0.8899853897094726
iter:   2100, loss: 0.8746527174115181
iter:   2200, loss: 0.85076611161232
iter:   2300, loss: 0.81531593978405
iter:   2400, loss: 0.8106295454502106
iter:   2500, loss: 0.770682820379734
iter:   2600, loss: 0.755650195479393
iter:   2700, loss: 0.7241431280970574
iter:   2800, loss: 0.7252260133624077
iter:   2900, loss: 0.6981255805492401
iter:   3000, loss: 0.7096511939167977
iter:   3100, loss: 0.6956504660844803
iter:   3200, loss: 0.6726438483595848
iter:   3300, loss: 0.6374849462509156
iter:   3400, loss: 0.6469437938928604
iter:   3500, loss: 0.6602672332525253
iter:   3600, loss: 0.6264837896823883
iter:   3700, loss: 0.6266887494921685
iter:   3800, loss: 0.6183856371045112
iter:   3900, loss: 0.6203207758069038
iter:   4000, loss: 0.6285728892683983
iter:   4100, loss: 0.5956749483942986
iter:   4200, loss: 0.5669044524431228
iter:   4300, loss: 0.5675328493118286
iter:   4400, loss: 0.5655387507379055
iter:   4500, loss: 0.5565882402658463
iter:   4600, loss: 0.5392079064249993
iter:   4700, loss: 0.5674674907326698
iter:   4800, loss: 0.5167884287238121
iter:   4900, loss: 0.5142209212481975
iter:   5000, loss: 0.5262074691057205
iter:   5100, loss: 0.4520773747563362
iter:   5200, loss: 0.4271890550851822
iter:   5300, loss: 0.4041162943840027
iter:   5400, loss: 0.4208503092825413
iter:   5500, loss: 0.4083712737262249
iter:   5600, loss: 0.374381337761879
iter:   5700, loss: 0.3802674071490765
iter:   5800, loss: 0.3855220194160938
iter:   5900, loss: 0.37254166811704637
iter:   6000, loss: 0.37549062609672545
iter:   6100, loss: 0.35655303329229354
iter:   6200, loss: 0.3832904715836048
iter:   6300, loss: 0.36069990441203115
iter:   6400, loss: 0.379711727052927
iter:   6500, loss: 0.3517957014590502
iter:   6600, loss: 0.36532109007239344
iter:   6700, loss: 0.3390779826045036
iter:   6800, loss: 0.33775138944387434
iter:   6900, loss: 0.3380255326628685
iter:   7000, loss: 0.3597500932216644
iter:   7100, loss: 0.34522622272372244
iter:   7200, loss: 0.30991335704922673
iter:   7300, loss: 0.3458643239736557
iter:   7400, loss: 0.3343860691785812
iter:   7500, loss: 0.32460676461458204
iter:   7600, loss: 0.3291155745089054
iter:   7700, loss: 0.33454544976353645
iter:   7800, loss: 0.3398377351462841
iter:   7900, loss: 0.31737824067473414
iter:   8000, loss: 0.31775048434734343
iter:   8100, loss: 0.3290546002238989
iter:   8200, loss: 0.32415148973464963
iter:   8300, loss: 0.3321322014927864
iter:   8400, loss: 0.310826424062252
iter:   8500, loss: 0.31858606077730656
iter:   8600, loss: 0.31780374482274054
iter:   8700, loss: 0.29977813482284543
iter:   8800, loss: 0.3226660566031933
iter:   8900, loss: 0.3172486248612404
iter:   9000, loss: 0.2986475954949856
iter:   9100, loss: 0.29794279783964156
iter:   9200, loss: 0.3126730825006962
iter:   9300, loss: 0.3092787253856659
iter:   9400, loss: 0.3208317855000496
iter:   9500, loss: 0.27555731028318403
iter:   9600, loss: 0.2851145999133587
iter:   9700, loss: 0.29426831260323527
iter:   9800, loss: 0.28938434027135373
iter:   9900, loss: 0.3054409822076559
iter:  10000, loss: 0.29251276470720766
iter:  10100, loss: 0.2802647940814495
iter:  10200, loss: 0.2748625036329031
iter:  10300, loss: 0.25462427303195
iter:  10400, loss: 0.24015042275190354
iter:  10500, loss: 0.2549858544766903
iter:  10600, loss: 0.2503721959143877
iter:  10700, loss: 0.2508306129276752
iter:  10800, loss: 0.2447423391789198
iter:  10900, loss: 0.24678486533463
iter:  11000, loss: 0.24113512843847273
iter:  11100, loss: 0.2646156495064497
iter:  11200, loss: 0.23368664942681788
iter:  11300, loss: 0.2587849972397089
iter:  11400, loss: 0.2303687861561775
iter:  11500, loss: 0.23894128143787385
iter:  11600, loss: 0.23465306255966425
iter:  11700, loss: 0.24974006421864034
iter:  11800, loss: 0.241383323892951
iter:  11900, loss: 0.2367060799151659
iter:  12000, loss: 0.24868167594075202
iter:  12100, loss: 0.23903766989707947
iter:  12200, loss: 0.2201935364305973
iter:  12300, loss: 0.23022219620645046
iter:  12400, loss: 0.2290211694687605
iter:  12500, loss: 0.23277755171060563
iter:  12600, loss: 0.23197760593146086
iter:  12700, loss: 0.23541068322956563
iter:  12800, loss: 0.22706845887005328
iter:  12900, loss: 0.23029980398714542
iter:  13000, loss: 0.21551739677786827
iter:  13100, loss: 0.22243980310857295
iter:  13200, loss: 0.23513729214668275
iter:  13300, loss: 0.25268827617168427
iter:  13400, loss: 0.21986203089356424
iter:  13500, loss: 0.21799783706665038
iter:  13600, loss: 0.21919313263148069
iter:  13700, loss: 0.2304950988292694
iter:  13800, loss: 0.22761393442749978
iter:  13900, loss: 0.22900705195963383
iter:  14000, loss: 0.22146457009017467
iter:  14100, loss: 0.2201124132424593
iter:  14200, loss: 0.21532218459993602
iter:  14300, loss: 0.22967133704572917
iter:  14400, loss: 0.2193044653534889
iter:  14500, loss: 0.19577493235468865
iter:  14600, loss: 0.22626231193542481
iter:  14700, loss: 0.2113846106082201
iter:  14800, loss: 0.22544626526534559
iter:  14900, loss: 0.20855571322143077
iter:  15000, loss: 0.20999090105295182
iter:  15100, loss: 0.19527383871376514
iter:  15200, loss: 0.20730998173356055
iter:  15300, loss: 0.2209079224616289
iter:  15400, loss: 0.1998010468482971
iter:  15500, loss: 0.2169014972448349
iter:  15600, loss: 0.20651703596115112
iter:  15700, loss: 0.2221830441057682
iter:  15800, loss: 0.19071514509618281
iter:  15900, loss: 0.19330411702394484
iter:  16000, loss: 0.20406786650419234
iter:  16100, loss: 0.20298186767846346
iter:  16200, loss: 0.20999172821640968
iter:  16300, loss: 0.19917022183537483
iter:  16400, loss: 0.20944709658622743
iter:  16500, loss: 0.21206474307924508
iter:  16600, loss: 0.19331652507185937
iter:  16700, loss: 0.1986208789795637
iter:  16800, loss: 0.18973630383610726
iter:  16900, loss: 0.20159271650016308
iter:  17000, loss: 0.21378545299172402
iter:  17100, loss: 0.19355530925095082
iter:  17200, loss: 0.20671781450510024
iter:  17300, loss: 0.19804086785763503
iter:  17400, loss: 0.20474628798663616
iter:  17500, loss: 0.19204643853008746
iter:  17600, loss: 0.19630358196794986
iter:  17700, loss: 0.20398525804281234
iter:  17800, loss: 0.2002621677517891
iter:  17900, loss: 0.20474877757951618
iter:  18000, loss: 0.19979893319308759
iter:  18100, loss: 0.18858987372368574
iter:  18200, loss: 0.1952048184350133
iter:  18300, loss: 0.20005133487284182
iter:  18400, loss: 0.20083362482488154
iter:  18500, loss: 0.20484512131661176
iter:  18600, loss: 0.20561253614723682
iter:  18700, loss: 0.18797347228974104
iter:  18800, loss: 0.20782538011670112
iter:  18900, loss: 0.20366565380245447
iter:  19000, loss: 0.18869645908474922
iter:  19100, loss: 0.198244753703475
iter:  19200, loss: 0.19936024017632006
iter:  19300, loss: 0.20316711518913508
iter:  19400, loss: 0.19834219612181186
iter:  19500, loss: 0.1988283358514309
iter:  19600, loss: 0.19042143132537603
iter:  19700, loss: 0.19643111109733583
iter:  19800, loss: 0.19699535991996528
iter:  19900, loss: 0.2085718022286892
iter:  20000, loss: 0.19828387439250947
iter:  20100, loss: 0.1949515998363495
iter:  20200, loss: 0.19440102193504571
iter:  20300, loss: 0.19798872398212553
iter:  20400, loss: 0.20704127673059702
iter:  20500, loss: 0.18543608844280243
iter:  20600, loss: 0.19421736676245926
iter:  20700, loss: 0.19632403317838906
iter:  20800, loss: 0.20124650985002518
iter:  20900, loss: 0.19041814994066952
iter:  21000, loss: 0.18789290331304073
iter:  21100, loss: 0.20401805110275745
iter:  21200, loss: 0.1991326382011175
iter:  21300, loss: 0.20342443492263557
iter:  21400, loss: 0.19349188715219498
iter:  21500, loss: 0.20321650840342045
iter:  21600, loss: 0.20012938652187587
iter:  21700, loss: 0.19490612670779228
iter:  21800, loss: 0.196647337526083
iter:  21900, loss: 0.1884653066471219
iter:  22000, loss: 0.20508720766752958
iter:  22100, loss: 0.19256477523595095
iter:  22200, loss: 0.19355389207601548
iter:  22300, loss: 0.18639315199106932
iter:  22400, loss: 0.1932257606089115
iter:  22500, loss: 0.194828517511487
iter:  22600, loss: 0.1866873539239168
iter:  22700, loss: 0.20068434074521066
iter:  22800, loss: 0.19476077996194363
iter:  22900, loss: 0.18913501292467116
iter:  23000, loss: 0.18583292372524737
iter:  23100, loss: 0.18671601135283708
iter:  23200, loss: 0.20611471440643073
iter:  23300, loss: 0.1875623245164752
iter:  23400, loss: 0.19535693231970072
iter:  23500, loss: 0.19190560061484574
iter:  23600, loss: 0.188289165571332
iter:  23700, loss: 0.20024907048791646
iter:  23800, loss: 0.1874644411355257
iter:  23900, loss: 0.20156278878450393
iter:  24000, loss: 0.20488083962351084
iter:  24100, loss: 0.18605501793324947
iter:  24200, loss: 0.19475614801049232
iter:  24300, loss: 0.17810789532959462
iter:  24400, loss: 0.20444013223052024
iter:  24500, loss: 0.20024137314409018
iter:  24600, loss: 0.19552674002945422
iter:  24700, loss: 0.1925056092068553
iter:  24800, loss: 0.17517160031944512
iter:  24900, loss: 0.1928630644455552
iter:  25000, loss: 0.20789931423962116
iter:  25100, loss: 0.19904507420957088
iter:  25200, loss: 0.19924212712794542
iter:  25300, loss: 0.19259076431393624
iter:  25400, loss: 0.1820298033580184
iter:  25500, loss: 0.1955521972849965
iter:  25600, loss: 0.18718354154378175
iter:  25700, loss: 0.1855504572764039
iter:  25800, loss: 0.1988561737537384
iter:  25900, loss: 0.196695108525455
iter:  26000, loss: 0.1839370260387659
iter:  26100, loss: 0.18433787275105715
iter:  26200, loss: 0.19719077430665494
iter:  26300, loss: 0.18178359922021628
iter:  26400, loss: 0.19298967182636262
iter:  26500, loss: 0.18347540408372878
iter:  26600, loss: 0.19746401727199556
iter:  26700, loss: 0.19341440044343472
iter:  26800, loss: 0.19679538205265998
iter:  26900, loss: 0.1934838315844536
iter:  27000, loss: 0.19432219270616768
iter:  27100, loss: 0.1892405679449439
iter:  27200, loss: 0.18812698908150197
iter:  27300, loss: 0.20029168702661992
iter:  27400, loss: 0.19869210980832577
iter:  27500, loss: 0.19089346259832382
iter:  27600, loss: 0.18946914497762918
iter:  27700, loss: 0.19363739661872387
iter:  27800, loss: 0.19135877925902606
iter:  27900, loss: 0.1935050904005766
iter:  28000, loss: 0.18215365175157786
iter:  28100, loss: 0.19827947877347468
iter:  28200, loss: 0.19872786562889813
iter:  28300, loss: 0.1978490912914276
iter:  28400, loss: 0.18069239668548107
iter:  28500, loss: 0.18685613863170147
iter:  28600, loss: 0.19118323273956775
iter:  28700, loss: 0.18554425865411758
iter:  28800, loss: 0.18655092548578978
iter:  28900, loss: 0.18373184714466334
iter:  29000, loss: 0.18433256786316632
iter:  29100, loss: 0.19435839205980301
iter:  29200, loss: 0.1989693695306778
iter:  29300, loss: 0.1860193670541048
iter:  29400, loss: 0.19533000562340022
iter:  29500, loss: 0.1939869164302945
iter:  29600, loss: 0.20487817145884038
iter:  29700, loss: 0.18516851723194122
iter:  29800, loss: 0.19489303771406413
iter:  29900, loss: 0.19169504195451736
iter:  30000, loss: 0.1846093262732029
iter:  30100, loss: 0.19512481033802032
iter:  30200, loss: 0.19241716425865887
iter:  30300, loss: 0.20328644953668118
iter:  30400, loss: 0.1854756412282586
iter:  30500, loss: 0.1833853414095938
iter:  30600, loss: 0.1915837612748146
iter:  30700, loss: 0.19796590153127908
iter:  30800, loss: 0.19170688215643167
iter:  30900, loss: 0.19033785969018935
iter:  31000, loss: 0.1764664639532566
iter:  31100, loss: 0.19575304873287677
iter:  31200, loss: 0.19618071049451827
iter:  31300, loss: 0.18633646849542856
iter:  31400, loss: 0.209361160248518
iter:  31500, loss: 0.19227863166481257
iter:  31600, loss: 0.1889881929010153
iter:  31700, loss: 0.19261198952794076
iter:  31800, loss: 0.1916776841133833
iter:  31900, loss: 0.17924372501671315
iter:  32000, loss: 0.19657922104001047

The final accuracy is: 88.95
The final error is: 11.05
correct ratio is: 0.889
